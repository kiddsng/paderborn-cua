{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules and libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# functions to create datasets and models\n",
    "from data.data import *\n",
    "from models.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available')\n",
    "else:\n",
    "    print('CUDA is available')\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Parameters for this experiment\"\"\"\n",
    "# params for loading the data\n",
    "path = 'data/Paderborn_FD/'\n",
    "source_domain = 'a'\n",
    "target_domains = ['b', 'c', 'd']\n",
    "best_accuracies = {'a': 0, 'b': 0, 'c': 0, 'd': 0}\n",
    "\n",
    "# params for configuring the model\n",
    "input_dim = 1\n",
    "hidden_dim = 256\n",
    "output_dim = 3\n",
    "drop_prob = 0.5\n",
    "\n",
    "# params for training the model\n",
    "epochs_pre = 20 # pre-training\n",
    "epochs = 20\n",
    "\n",
    "# optimizing the model\n",
    "lr = 1e-4\n",
    "d_lr = 1e-4\n",
    "batch_size = 20\n",
    "beta1 = 0.5\n",
    "beta2 = 0.9\n",
    "lambda_rpy = 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 1, 5120)\n"
     ]
    }
   ],
   "source": [
    "# source domain data for training, validating and testing\n",
    "train_dataloader_src, val_dataloader_src, test_dataloader_src = generate_dataloaders(path, source_domain, batch_size)\n",
    "\n",
    "# target domain data for validating and testing\n",
    "train_dataloader_tgt, val_dataloader_tgt, test_dataloader_tgt = [], [], []\n",
    "for target_domain in target_domains:\n",
    "    train_dataloader_temp, val_dataloader_temp, test_dataloader_temp = generate_dataloaders(path, target_domain, batch_size)\n",
    "    \n",
    "    train_dataloader_tgt.append(train_dataloader_temp)\n",
    "    val_dataloader_tgt.append(val_dataloader_temp)\n",
    "    test_dataloader_tgt.append(test_dataloader_temp)\n",
    "\n",
    "# replay data for CDA\n",
    "replay_dataset = ReplayDataset(train_dataloader_src.dataset)\n",
    "replay_dataloader = DataLoader(dataset=replay_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_src = Encoder_AMDA(\n",
    "    input_dim=input_dim, # 1D input (sensor readings)\n",
    "    hidden_dim=hidden_dim # hidden layers 64\n",
    ")\n",
    "\n",
    "classifier = Classifier_AMDA(\n",
    "    hidden_dim=hidden_dim, # hidden layers 64\n",
    "    output_dim=output_dim, # 3 classes (healthy, inner- and outer-bearing damages)\n",
    "    dropout=drop_prob # dropout prob 0.5\n",
    ")\n",
    "\n",
    "encoder_tgt = Encoder_AMDA(\n",
    "    input_dim=input_dim, # 1D input (sensor readings)\n",
    "    hidden_dim=hidden_dim, # hidden layers 64\n",
    ")\n",
    "\n",
    "discriminator = Discriminator(\n",
    "    hidden_dim=hidden_dim\n",
    ")\n",
    "\n",
    "if train_on_gpu:\n",
    "    encoder_src = encoder_src.to(device)\n",
    "    classifier = classifier.to(device)\n",
    "    encoder_tgt = encoder_tgt.to(device)\n",
    "    discriminator = discriminator.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for training source encoder and shared classifier\n",
    "def train_src(encoder, classifier):\n",
    "    \"\"\"Train the source encoder and shared classifier on source domain\"\"\"\n",
    "    encoder.train()\n",
    "    classifier.train()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(\n",
    "        list(encoder.parameters()) + list(classifier.parameters()),\n",
    "        lr=lr,\n",
    "        betas=(beta1, beta2)\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs_pre):\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "\n",
    "        for batch_idx, (x_src, y_src) in enumerate(train_dataloader_src):\n",
    "            if train_on_gpu:\n",
    "                x_src, y_src = x_src.to(device), y_src.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            e_src = encoder(x_src)\n",
    "            # print(e_src.shape)\n",
    "            # print(e_src)\n",
    "            pred_src = classifier(e_src)\n",
    "            # print(pred_src)\n",
    "            # print(y_src)\n",
    "            loss_src = criterion(pred_src, y_src)\n",
    "            loss_src.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss_src.detach().item()) # detach the loss from compute graph\n",
    "            # print('1')\n",
    "            # print(y_src)\n",
    "            # print('2')\n",
    "            # print(pred_src.detach().argmax(dim=1))\n",
    "            # print('3')\n",
    "            # print(y_src.eq(pred_src.detach().argmax(dim=1)))\n",
    "            # print('4')\n",
    "            # print(y_src.eq(pred_src.detach().argmax(dim=1)).float())\n",
    "            # print('5')\n",
    "            # print(y_src.eq(pred_src.detach().argmax(dim=1)).float().mean())\n",
    "            accuracies.append(y_src.eq(pred_src.detach().argmax(dim=1)).float().mean())\n",
    "        \n",
    "        # print for each epoch\n",
    "        print(f'Epoch: {epoch + 1} \\n \\t Train Loss:{torch.tensor(losses).mean():0.2f} \\t Train Acc:{torch.tensor(accuracies).mean():0.2f}')\n",
    "\n",
    "        # for each epoch, evaluate your model on the validation data\n",
    "        val_loss, val_acc = evaluate_src(encoder, classifier, phase = 'Val')\n",
    "        print(f'\\t Val Loss:{val_loss:0.2f} \\t\\t Val Acc:{val_acc:0.2f}')\n",
    "\n",
    "    return encoder, classifier\n",
    "\n",
    "def evaluate_src(encoder, classifier, phase='Val'): # phase can be validate or test\n",
    "    \"\"\"Evaluate the trained network on source domain\"\"\"\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    dataloader = val_dataloader_src if phase == 'Val' else test_dataloader_src\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x_src, y_src) in enumerate(dataloader):\n",
    "            if train_on_gpu:\n",
    "                x_src, y_src = x_src.to(device), y_src.to(device)\n",
    "\n",
    "            e_src = encoder(x_src)\n",
    "            pred_src = classifier(e_src)\n",
    "            loss_src = criterion(pred_src, y_src)\n",
    "            \n",
    "            # append loss for each batch\n",
    "            losses.append(loss_src.detach().item()) # detach the loss from compute graph \n",
    "            accuracies.append(y_src.eq(pred_src.detach().argmax(dim=1)).float().mean())\n",
    "  \n",
    "        mean_loss = torch.tensor(losses).mean()\n",
    "        mean_acc = torch.tensor(accuracies).mean()\n",
    "        if dataloader == test_dataloader_src:\n",
    "            best_accuracies[source_domain] = max(best_accuracies[source_domain], mean_acc)\n",
    "        return mean_loss, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous Unsupervised Adaptation (CUA)\n",
    "# functions for training target encoder\n",
    "def train_tgt(encoder_src, encoder_tgt, classifier, discriminator, phase):\n",
    "    \"\"\"Train the target encoder on target domains with source encoder and test the network\"\"\"\n",
    "    encoder_tgt.train()\n",
    "    discriminator.train()\n",
    "    classifier.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(\n",
    "        encoder_tgt.parameters(),\n",
    "        lr=lr,\n",
    "        betas=(beta1, beta2)\n",
    "    )\n",
    "    d_optimizer = Adam(\n",
    "        discriminator.parameters(),\n",
    "        lr=d_lr,\n",
    "        betas=(beta1, beta2)\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        losses_d = []\n",
    "        losses_tgt = []\n",
    "        losses_rpy = []\n",
    "        accuracies = []\n",
    "        accuracies_d = []\n",
    "\n",
    "        for batch_idx, ((x_src, y_src), (x_tgt, y_tgt), (x_rpy, y_rpy)) in enumerate(zip(train_dataloader_src, train_dataloader_tgt[phase], replay_dataloader)):\n",
    "            if(train_on_gpu):\n",
    "                x_src, y_src = x_src.to(device), y_src.to(device)\n",
    "                x_tgt, y_tgt = x_tgt.to(device), y_tgt.to(device)\n",
    "                x_rpy, y_rpy = x_rpy.to(device), y_rpy.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            # part 1: sequential unsupervised adaptation\n",
    "            # learn e_src and _tgt: source and target mapping represenations\n",
    "            e_src = encoder_src(x_src)\n",
    "            e_tgt = encoder_tgt(x_tgt)\n",
    "            e_concat = torch.concat((e_src.detach(), e_tgt.detach()), 0)\n",
    "            # minimize distance between source and target empirical mapping distribution using adversarial discriminator\n",
    "            d_concat = discriminator(e_concat)\n",
    "\n",
    "            label_src = Variable(torch.ones(e_src.size(0)).long()).to(device)\n",
    "            label_tgt = Variable(torch.zeros(e_tgt.size(0)).long()).to(device)\n",
    "            label_concat = torch.cat((label_src, label_tgt), 0)\n",
    "\n",
    "            loss_d = criterion(d_concat, label_concat)\n",
    "            loss_d.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            e_tgt = encoder_tgt(x_tgt)\n",
    "            pred_tgt = classifier(e_tgt)\n",
    "            d_tgt = discriminator(e_tgt)\n",
    "            label_tgt = Variable(torch.ones(e_tgt.size(0)).long()).to(device)\n",
    "            loss_tgt = criterion(d_tgt, label_tgt)\n",
    "\n",
    "            # part 2: continuous replay adaptation\n",
    "            # additional replay loss to retain 'prior knowledge'\n",
    "            pred_rpy = classifier(encoder_tgt(x_rpy))\n",
    "            loss_rpy = criterion(pred_rpy, y_rpy)\n",
    "            loss = loss_tgt + lambda_rpy * loss_rpy\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # training (with replay) losses and accuracies\n",
    "            losses.append(loss.detach().item()) # detach the loss from compute graph\n",
    "            losses_d.append(loss_d.detach().item())\n",
    "            losses_tgt.append(loss_tgt.detach().item())\n",
    "            losses_rpy.append(loss_rpy.detach().item())\n",
    "            accuracies.append(y_tgt.eq(pred_tgt.detach().argmax(dim=1)).float().mean())\n",
    "            accuracies_d.append(torch.squeeze(d_concat.max(1)[1]).eq(label_concat.detach()).float().mean())\n",
    "        \n",
    "        # print for each epoch\n",
    "        print(f'Epoch: {epoch + 1} \\n \\t Train Loss:{torch.tensor(losses).mean():0.2f} \\t Train Acc:{torch.tensor(accuracies).mean():0.2f}')\n",
    "        print(f'\\t Discriminator Loss:{torch.tensor(losses_d).mean():0.2f} \\t Train (Replay) Loss:{torch.tensor(losses_rpy).mean():0.2f} \\t Train (Adversarial) Loss:{torch.tensor(losses_tgt).mean():0.2f}')\n",
    "        \n",
    "        # for each epoch, evaluate your model on the validation data\n",
    "        val_loss, val_acc = evaluate_tgt(encoder_tgt, classifier, val_dataloader_tgt[phase])\n",
    "        print(f'\\t Val (with Target) Loss:{val_loss:0.2f} \\t Val (with Target) Acc:{val_acc:0.2f}')\n",
    "\n",
    "    return encoder_tgt\n",
    "    \n",
    "# testing model on target domains\n",
    "\n",
    "def evaluate_tgt(encoder, classifier, dataloader):\n",
    "    \"\"\"Evaluate the network on current target domain\"\"\"\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, y) in enumerate(dataloader): # target dataloader\n",
    "            if(train_on_gpu):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "            pred_tgt = classifier(encoder(x))\n",
    "            loss_tgt = criterion(pred_tgt, y)\n",
    "            \n",
    "            # append loss for each batch\n",
    "            losses.append(loss_tgt.detach().item()) # detach the loss from compute graph \n",
    "            accuracies.append(y.eq(pred_tgt.detach().argmax(dim=1)).float().mean())\n",
    "            \n",
    "        mean_loss = torch.tensor(losses).mean()\n",
    "        mean_acc = torch.tensor(accuracies).mean()\n",
    "        if dataloader in test_dataloader_tgt:\n",
    "            index = test_dataloader_tgt.index(dataloader)\n",
    "            best_accuracies[target_domains[index]] = max(best_accuracies[target_domains[index]], mean_acc)\n",
    "\n",
    "        return mean_loss, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample previously seen examples and their respective classification scores as 'soft labels' from the target domains\n",
    "def generate_data_tuple(encoder_tgt, classifier, dataloader):\n",
    "    print('===> generate new replay dataset!')\n",
    "    encoder_tgt.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    m = nn.Softmax(dim=1)\n",
    "\n",
    "    all_x, all_pred = [], []\n",
    "    accuracies = []\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x_tgt, y_tgt) in enumerate(dataloader):\n",
    "            if(train_on_gpu):\n",
    "                x_tgt, y_tgt = x_tgt.to(device), y_tgt.to(device)\n",
    "\n",
    "            # perform classification with the target mapping representations\n",
    "            pred_tgt = classifier(encoder_tgt(x_tgt))\n",
    "            pred_tgt_softmax = m(pred_tgt)\n",
    "            confidence_level = pred_tgt_softmax.amax(axis=1)\n",
    "\n",
    "            all_x.append(to_np(torch.squeeze(x_tgt[np.nonzero(confidence_level > 0.9)], 1)))\n",
    "            all_pred.append(to_np(torch.squeeze(pred_tgt.detach().argmax(dim=1)[np.nonzero(confidence_level > 0.9)], 1)))\n",
    "            accuracies.append(y_tgt[np.nonzero(confidence_level > 0.9)].eq(torch.squeeze(pred_tgt.detach().argmax(dim=1)[np.nonzero(confidence_level > 0.9)], 0)).float().mean())\n",
    "            \n",
    "        x, pred = np.concatenate(all_x, 0), np.concatenate(all_pred, 0)\n",
    "        num_samples = x.shape[0]\n",
    "        num_subsamples = int(0.01 * num_samples)\n",
    "        np.random.seed(4154)\n",
    "        perm = np.random.permutation(num_samples)\n",
    "        x, pred = x[perm[0:num_subsamples]], pred[perm[0:num_subsamples]]\n",
    "\n",
    "        print('generated: ', x.shape, pred.shape, 'accuracy: ', torch.tensor(accuracies).mean())\n",
    "        return x, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-training\n",
    "# encoder_src, classifier = train_src(encoder_src, classifier)\n",
    "# torch.save(encoder_src.state_dict(), './dump/source_encoder.pt')\n",
    "# torch.save(classifier.state_dict(), './dump/classifier.pt')\n",
    "encoder_src.load_state_dict(torch.load('./dump/source_encoder.pt'))\n",
    "classifier.load_state_dict(torch.load('./dump/classifier.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 1 (Domain a to Domain b)\n",
      "Epoch: 1 \n",
      " \t Train Loss:1.35 \t Train Acc:0.59\n",
      "\t Discriminator Loss:0.63 \t Train (Replay) Loss:0.10 \t Train (Adversarial) Loss:1.35\n",
      "\t Val (with Target) Loss:15.16 \t Val (with Target) Acc:0.57\n",
      "Epoch: 2 \n",
      " \t Train Loss:1.38 \t Train Acc:0.49\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.32 \t Train (Adversarial) Loss:1.37\n",
      "\t Val (with Target) Loss:12.66 \t Val (with Target) Acc:0.59\n",
      "Epoch: 3 \n",
      " \t Train Loss:1.27 \t Train Acc:0.69\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.51 \t Train (Adversarial) Loss:1.25\n",
      "\t Val (with Target) Loss:15.62 \t Val (with Target) Acc:0.52\n",
      "Epoch: 4 \n",
      " \t Train Loss:1.16 \t Train Acc:0.59\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.61 \t Train (Adversarial) Loss:1.14\n",
      "\t Val (with Target) Loss:16.37 \t Val (with Target) Acc:0.48\n",
      "Epoch: 5 \n",
      " \t Train Loss:1.20 \t Train Acc:0.55\n",
      "\t Discriminator Loss:0.61 \t Train (Replay) Loss:0.80 \t Train (Adversarial) Loss:1.18\n",
      "\t Val (with Target) Loss:17.67 \t Val (with Target) Acc:0.44\n",
      "Epoch: 6 \n",
      " \t Train Loss:1.24 \t Train Acc:0.49\n",
      "\t Discriminator Loss:0.57 \t Train (Replay) Loss:0.97 \t Train (Adversarial) Loss:1.21\n",
      "\t Val (with Target) Loss:14.86 \t Val (with Target) Acc:0.48\n",
      "Epoch: 7 \n",
      " \t Train Loss:1.20 \t Train Acc:0.50\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.62 \t Train (Adversarial) Loss:1.18\n",
      "\t Val (with Target) Loss:12.27 \t Val (with Target) Acc:0.51\n",
      "Epoch: 8 \n",
      " \t Train Loss:1.10 \t Train Acc:0.59\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:2.81 \t Train (Adversarial) Loss:1.01\n",
      "\t Val (with Target) Loss:8.10 \t Val (with Target) Acc:0.62\n",
      "Epoch: 9 \n",
      " \t Train Loss:1.10 \t Train Acc:0.64\n",
      "\t Discriminator Loss:0.71 \t Train (Replay) Loss:1.15 \t Train (Adversarial) Loss:1.06\n",
      "\t Val (with Target) Loss:7.33 \t Val (with Target) Acc:0.63\n",
      "Epoch: 10 \n",
      " \t Train Loss:0.98 \t Train Acc:0.58\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:1.19 \t Train (Adversarial) Loss:0.95\n",
      "\t Val (with Target) Loss:9.60 \t Val (with Target) Acc:0.55\n",
      "Epoch: 11 \n",
      " \t Train Loss:0.98 \t Train Acc:0.51\n",
      "\t Discriminator Loss:0.63 \t Train (Replay) Loss:0.59 \t Train (Adversarial) Loss:0.96\n",
      "\t Val (with Target) Loss:17.84 \t Val (with Target) Acc:0.44\n",
      "Epoch: 12 \n",
      " \t Train Loss:0.94 \t Train Acc:0.45\n",
      "\t Discriminator Loss:0.58 \t Train (Replay) Loss:0.46 \t Train (Adversarial) Loss:0.92\n",
      "\t Val (with Target) Loss:13.90 \t Val (with Target) Acc:0.48\n",
      "Epoch: 13 \n",
      " \t Train Loss:1.02 \t Train Acc:0.54\n",
      "\t Discriminator Loss:0.58 \t Train (Replay) Loss:0.51 \t Train (Adversarial) Loss:1.00\n",
      "\t Val (with Target) Loss:6.31 \t Val (with Target) Acc:0.65\n",
      "Epoch: 14 \n",
      " \t Train Loss:1.08 \t Train Acc:0.68\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:1.41 \t Train (Adversarial) Loss:1.04\n",
      "\t Val (with Target) Loss:4.96 \t Val (with Target) Acc:0.69\n",
      "Epoch: 15 \n",
      " \t Train Loss:0.97 \t Train Acc:0.78\n",
      "\t Discriminator Loss:0.59 \t Train (Replay) Loss:0.66 \t Train (Adversarial) Loss:0.95\n",
      "\t Val (with Target) Loss:6.09 \t Val (with Target) Acc:0.64\n",
      "Epoch: 16 \n",
      " \t Train Loss:0.97 \t Train Acc:0.58\n",
      "\t Discriminator Loss:0.55 \t Train (Replay) Loss:0.32 \t Train (Adversarial) Loss:0.96\n",
      "\t Val (with Target) Loss:6.93 \t Val (with Target) Acc:0.61\n",
      "Epoch: 17 \n",
      " \t Train Loss:1.10 \t Train Acc:0.60\n",
      "\t Discriminator Loss:0.54 \t Train (Replay) Loss:0.75 \t Train (Adversarial) Loss:1.07\n",
      "\t Val (with Target) Loss:4.40 \t Val (with Target) Acc:0.72\n",
      "Epoch: 18 \n",
      " \t Train Loss:0.96 \t Train Acc:0.85\n",
      "\t Discriminator Loss:0.58 \t Train (Replay) Loss:0.47 \t Train (Adversarial) Loss:0.94\n",
      "\t Val (with Target) Loss:5.31 \t Val (with Target) Acc:0.67\n",
      "Epoch: 19 \n",
      " \t Train Loss:0.92 \t Train Acc:0.71\n",
      "\t Discriminator Loss:0.59 \t Train (Replay) Loss:0.54 \t Train (Adversarial) Loss:0.91\n",
      "\t Val (with Target) Loss:5.19 \t Val (with Target) Acc:0.68\n",
      "Epoch: 20 \n",
      " \t Train Loss:0.85 \t Train Acc:0.71\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.43 \t Train (Adversarial) Loss:0.83\n",
      "\t Val (with Target) Loss:6.88 \t Val (with Target) Acc:0.61\n",
      "\n",
      "Testing Accuracy on Previously Seen and Current Domains:\n",
      "Source Domain a:\n",
      "\t Test (with Source) Loss:0.50 \t Test (with Source) Acc:0.83\n",
      "Target Domain b:\n",
      "\t Test (with Target) Loss:6.76 \t Test (with Target) Acc:0.59\n",
      "===> generate new replay dataset!\n",
      "generated:  (77, 1, 5120) (77,) accuracy:  tensor(0.6099)\n",
      "157\n",
      "\n",
      "Phase 2 (Domain b to Domain c)\n",
      "Epoch: 1 \n",
      " \t Train Loss:0.74 \t Train Acc:0.73\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.41 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:3.43 \t Val (with Target) Acc:0.78\n",
      "Epoch: 2 \n",
      " \t Train Loss:0.75 \t Train Acc:0.71\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:0.51 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:3.22 \t Val (with Target) Acc:0.77\n",
      "Epoch: 3 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:0.82 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:3.42 \t Val (with Target) Acc:0.76\n",
      "Epoch: 4 \n",
      " \t Train Loss:0.76 \t Train Acc:0.72\n",
      "\t Discriminator Loss:0.63 \t Train (Replay) Loss:0.35 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:4.09 \t Val (with Target) Acc:0.72\n",
      "Epoch: 5 \n",
      " \t Train Loss:0.72 \t Train Acc:0.79\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:0.35 \t Train (Adversarial) Loss:0.71\n",
      "\t Val (with Target) Loss:3.45 \t Val (with Target) Acc:0.74\n",
      "Epoch: 6 \n",
      " \t Train Loss:0.72 \t Train Acc:0.67\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:0.52 \t Train (Adversarial) Loss:0.71\n",
      "\t Val (with Target) Loss:2.73 \t Val (with Target) Acc:0.77\n",
      "Epoch: 7 \n",
      " \t Train Loss:0.70 \t Train Acc:0.77\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:0.27 \t Train (Adversarial) Loss:0.70\n",
      "\t Val (with Target) Loss:2.81 \t Val (with Target) Acc:0.77\n",
      "Epoch: 8 \n",
      " \t Train Loss:0.69 \t Train Acc:0.80\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:0.19 \t Train (Adversarial) Loss:0.68\n",
      "\t Val (with Target) Loss:2.49 \t Val (with Target) Acc:0.77\n",
      "Epoch: 9 \n",
      " \t Train Loss:0.72 \t Train Acc:0.75\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:0.51 \t Train (Adversarial) Loss:0.70\n",
      "\t Val (with Target) Loss:2.83 \t Val (with Target) Acc:0.77\n",
      "Epoch: 10 \n",
      " \t Train Loss:0.72 \t Train Acc:0.68\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.58 \t Train (Adversarial) Loss:0.70\n",
      "\t Val (with Target) Loss:4.45 \t Val (with Target) Acc:0.70\n",
      "Epoch: 11 \n",
      " \t Train Loss:0.71 \t Train Acc:0.75\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:0.58 \t Train (Adversarial) Loss:0.70\n",
      "\t Val (with Target) Loss:4.37 \t Val (with Target) Acc:0.73\n",
      "Epoch: 12 \n",
      " \t Train Loss:0.72 \t Train Acc:0.78\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:0.35 \t Train (Adversarial) Loss:0.71\n",
      "\t Val (with Target) Loss:3.35 \t Val (with Target) Acc:0.75\n",
      "Epoch: 13 \n",
      " \t Train Loss:0.70 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.45 \t Train (Adversarial) Loss:0.68\n",
      "\t Val (with Target) Loss:2.58 \t Val (with Target) Acc:0.76\n",
      "Epoch: 14 \n",
      " \t Train Loss:0.73 \t Train Acc:0.76\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:0.69 \t Train (Adversarial) Loss:0.71\n",
      "\t Val (with Target) Loss:2.20 \t Val (with Target) Acc:0.77\n",
      "Epoch: 15 \n",
      " \t Train Loss:0.74 \t Train Acc:0.77\n",
      "\t Discriminator Loss:0.63 \t Train (Replay) Loss:0.60 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:3.03 \t Val (with Target) Acc:0.75\n",
      "Epoch: 16 \n",
      " \t Train Loss:0.72 \t Train Acc:0.78\n",
      "\t Discriminator Loss:0.63 \t Train (Replay) Loss:0.16 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:3.67 \t Val (with Target) Acc:0.74\n",
      "Epoch: 17 \n",
      " \t Train Loss:0.76 \t Train Acc:0.78\n",
      "\t Discriminator Loss:0.61 \t Train (Replay) Loss:0.44 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:3.29 \t Val (with Target) Acc:0.74\n",
      "Epoch: 18 \n",
      " \t Train Loss:0.69 \t Train Acc:0.76\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:0.33 \t Train (Adversarial) Loss:0.68\n",
      "\t Val (with Target) Loss:3.67 \t Val (with Target) Acc:0.71\n",
      "Epoch: 19 \n",
      " \t Train Loss:0.73 \t Train Acc:0.74\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.33 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:3.24 \t Val (with Target) Acc:0.75\n",
      "Epoch: 20 \n",
      " \t Train Loss:0.78 \t Train Acc:0.73\n",
      "\t Discriminator Loss:0.59 \t Train (Replay) Loss:0.26 \t Train (Adversarial) Loss:0.78\n",
      "\t Val (with Target) Loss:2.54 \t Val (with Target) Acc:0.77\n",
      "\n",
      "Testing Accuracy on Previously Seen and Current Domains:\n",
      "Source Domain a:\n",
      "\t Test (with Source) Loss:0.46 \t Test (with Source) Acc:0.76\n",
      "Target Domain b:\n",
      "\t Test (with Target) Loss:4.75 \t Test (with Target) Acc:0.62\n",
      "Target Domain c:\n",
      "\t Test (with Target) Loss:2.80 \t Test (with Target) Acc:0.74\n",
      "===> generate new replay dataset!\n",
      "generated:  (78, 1, 5120) (78,) accuracy:  tensor(0.7591)\n",
      "235\n",
      "\n",
      "Phase 3 (Domain c to Domain d)\n",
      "Epoch: 1 \n",
      " \t Train Loss:0.76 \t Train Acc:0.69\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.38 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:2.70 \t Val (with Target) Acc:0.68\n",
      "Epoch: 2 \n",
      " \t Train Loss:0.77 \t Train Acc:0.69\n",
      "\t Discriminator Loss:0.61 \t Train (Replay) Loss:0.77 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:2.48 \t Val (with Target) Acc:0.67\n",
      "Epoch: 3 \n",
      " \t Train Loss:0.71 \t Train Acc:0.77\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.89 \t Train (Adversarial) Loss:0.68\n",
      "\t Val (with Target) Loss:2.33 \t Val (with Target) Acc:0.69\n",
      "Epoch: 4 \n",
      " \t Train Loss:0.78 \t Train Acc:0.68\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:0.45 \t Train (Adversarial) Loss:0.76\n",
      "\t Val (with Target) Loss:1.63 \t Val (with Target) Acc:0.70\n",
      "Epoch: 5 \n",
      " \t Train Loss:0.74 \t Train Acc:0.70\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.28 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:2.00 \t Val (with Target) Acc:0.72\n",
      "Epoch: 6 \n",
      " \t Train Loss:0.77 \t Train Acc:0.77\n",
      "\t Discriminator Loss:0.61 \t Train (Replay) Loss:0.17 \t Train (Adversarial) Loss:0.77\n",
      "\t Val (with Target) Loss:2.08 \t Val (with Target) Acc:0.70\n",
      "Epoch: 7 \n",
      " \t Train Loss:0.77 \t Train Acc:0.70\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.24 \t Train (Adversarial) Loss:0.77\n",
      "\t Val (with Target) Loss:1.27 \t Val (with Target) Acc:0.74\n",
      "Epoch: 8 \n",
      " \t Train Loss:0.73 \t Train Acc:0.71\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.39 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:2.07 \t Val (with Target) Acc:0.72\n",
      "Epoch: 9 \n",
      " \t Train Loss:0.78 \t Train Acc:0.71\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.19 \t Train (Adversarial) Loss:0.77\n",
      "\t Val (with Target) Loss:1.88 \t Val (with Target) Acc:0.70\n",
      "Epoch: 10 \n",
      " \t Train Loss:0.75 \t Train Acc:0.70\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:0.52 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.85 \t Val (with Target) Acc:0.74\n",
      "Epoch: 11 \n",
      " \t Train Loss:0.74 \t Train Acc:0.74\n",
      "\t Discriminator Loss:0.63 \t Train (Replay) Loss:0.47 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:1.85 \t Val (with Target) Acc:0.72\n",
      "Epoch: 12 \n",
      " \t Train Loss:0.79 \t Train Acc:0.69\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.35 \t Train (Adversarial) Loss:0.78\n",
      "\t Val (with Target) Loss:1.83 \t Val (with Target) Acc:0.71\n",
      "Epoch: 13 \n",
      " \t Train Loss:0.79 \t Train Acc:0.67\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.20 \t Train (Adversarial) Loss:0.78\n",
      "\t Val (with Target) Loss:2.26 \t Val (with Target) Acc:0.68\n",
      "Epoch: 14 \n",
      " \t Train Loss:0.81 \t Train Acc:0.76\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.45 \t Train (Adversarial) Loss:0.80\n",
      "\t Val (with Target) Loss:2.17 \t Val (with Target) Acc:0.68\n",
      "Epoch: 15 \n",
      " \t Train Loss:0.78 \t Train Acc:0.72\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.18 \t Train (Adversarial) Loss:0.78\n",
      "\t Val (with Target) Loss:3.02 \t Val (with Target) Acc:0.67\n",
      "Epoch: 16 \n",
      " \t Train Loss:0.81 \t Train Acc:0.71\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.13 \t Train (Adversarial) Loss:0.81\n",
      "\t Val (with Target) Loss:1.59 \t Val (with Target) Acc:0.73\n",
      "Epoch: 17 \n",
      " \t Train Loss:0.79 \t Train Acc:0.77\n",
      "\t Discriminator Loss:0.63 \t Train (Replay) Loss:0.81 \t Train (Adversarial) Loss:0.77\n",
      "\t Val (with Target) Loss:1.95 \t Val (with Target) Acc:0.74\n",
      "Epoch: 18 \n",
      " \t Train Loss:0.83 \t Train Acc:0.72\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.70 \t Train (Adversarial) Loss:0.81\n",
      "\t Val (with Target) Loss:2.04 \t Val (with Target) Acc:0.73\n",
      "Epoch: 19 \n",
      " \t Train Loss:0.86 \t Train Acc:0.75\n",
      "\t Discriminator Loss:0.59 \t Train (Replay) Loss:0.21 \t Train (Adversarial) Loss:0.86\n",
      "\t Val (with Target) Loss:1.56 \t Val (with Target) Acc:0.74\n",
      "Epoch: 20 \n",
      " \t Train Loss:0.79 \t Train Acc:0.73\n",
      "\t Discriminator Loss:0.61 \t Train (Replay) Loss:0.38 \t Train (Adversarial) Loss:0.77\n",
      "\t Val (with Target) Loss:2.51 \t Val (with Target) Acc:0.67\n",
      "\n",
      "Testing Accuracy on Previously Seen and Current Domains:\n",
      "Source Domain a:\n",
      "\t Test (with Source) Loss:0.44 \t Test (with Source) Acc:0.77\n",
      "Target Domain b:\n",
      "\t Test (with Target) Loss:6.37 \t Test (with Target) Acc:0.52\n",
      "Target Domain c:\n",
      "\t Test (with Target) Loss:3.12 \t Test (with Target) Acc:0.72\n",
      "Target Domain d:\n",
      "\t Test (with Target) Loss:2.51 \t Test (with Target) Acc:0.67\n",
      "===> generate new replay dataset!\n",
      "generated:  (76, 1, 5120) (76,) accuracy:  tensor(0.6858)\n",
      "311\n"
     ]
    }
   ],
   "source": [
    "encoder_tgt.load_state_dict(encoder_src.state_dict())\n",
    "\n",
    "# adaptation\n",
    "for phase in range(len(target_domains)):\n",
    "    if(phase == 0): # Domain A to B\n",
    "        print(f'\\nPhase {phase + 1} (Domain {source_domain} to Domain {target_domains[phase]})')\n",
    "    else: # Domain B to C, and Domain C to D\n",
    "        print(f'\\nPhase {phase + 1} (Domain {target_domains[phase - 1]} to Domain {target_domains[phase]})')\n",
    "    \n",
    "    encoder_tgt = train_tgt(encoder_src, encoder_tgt, classifier, discriminator, phase)\n",
    "    \n",
    "    print('\\nTesting Accuracy on Previously Seen and Current Domains:')\n",
    "    print(f'Source Domain {source_domain}:')\n",
    "    src_test_loss, src_test_acc = evaluate_src(encoder_tgt, classifier, phase='Test')\n",
    "    print(f'\\t Test (with Source) Loss:{src_test_loss:0.2f} \\t Test (with Source) Acc:{src_test_acc:0.2f}') \n",
    "    for p in range(phase + 1):\n",
    "        print(f'Target Domain {target_domains[p]}:')\n",
    "        tgt_test_loss, tgt_test_acc = evaluate_tgt(encoder_tgt, classifier, test_dataloader_tgt[p])\n",
    "        print(f'\\t Test (with Target) Loss:{tgt_test_loss:0.2f} \\t Test (with Target) Acc:{tgt_test_acc:0.2f}')\n",
    "        \n",
    "    # update replay data and dataloader\n",
    "    data_tuple = generate_data_tuple(encoder_tgt, classifier, train_dataloader_tgt[phase])\n",
    "    replay_dataset.replay_dataset.update(data_tuple)\n",
    "    print(replay_dataset.__len__())\n",
    "    replay_dataloader = DataLoader(dataset=replay_dataset, shuffle=True, batch_size=batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Test (with Source) Loss:0.43 \t Test (with Source) Acc:0.77\n",
      "\n",
      "Phase 1 (Domain a to Domain b)\n",
      "\t Test (with Target) Loss:6.37 \t Test (with Target) Acc:0.52\n",
      "\n",
      "Phase 2 (Domain b to Domain c)\n",
      "\t Test (with Target) Loss:3.15 \t Test (with Target) Acc:0.71\n",
      "\n",
      "Phase 3 (Domain c to Domain d)\n",
      "\t Test (with Target) Loss:2.51 \t Test (with Target) Acc:0.67\n"
     ]
    }
   ],
   "source": [
    "src_test_loss, src_test_acc = evaluate_src(encoder_tgt, classifier, phase='Test')\n",
    "print(f'\\t Test (with Source) Loss:{src_test_loss:0.2f} \\t Test (with Source) Acc:{src_test_acc:0.2f}') \n",
    "for phase in range(len(target_domains)):\n",
    "    if(phase == 0): # Domain A to B\n",
    "        print(f'\\nPhase {phase + 1} (Domain {source_domain} to Domain {target_domains[phase]})')\n",
    "    else: # Domain B to C, and Domain C to D\n",
    "        print(f'\\nPhase {phase + 1} (Domain {target_domains[phase - 1]} to Domain {target_domains[phase]})')\n",
    "    \n",
    "    tgt_test_loss, tgt_test_acc = evaluate_tgt(encoder_tgt, classifier, test_dataloader_tgt[phase])\n",
    "    print(f'\\t Test (with Target) Loss:{tgt_test_loss:0.2f} \\t Test (with Target) Acc:{tgt_test_acc:0.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': tensor(0.8316),\n",
       " 'b': tensor(0.6153),\n",
       " 'c': tensor(0.7385),\n",
       " 'd': tensor(0.6661)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83\n"
     ]
    }
   ],
   "source": [
    "print(f\"{best_accuracies['a']:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = list(best_accuracies.keys())\n",
    "accuracies = list(best_accuracies.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x254e4cbe8b0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(domains, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('cda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1e22e9a36d2ff643870da04044e3ba6e20e322fec5858ad637bee34c459619d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
