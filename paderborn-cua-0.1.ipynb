{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules and libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# functions to create datasets and models\n",
    "from data.data import *\n",
    "from models.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3639,  1.4954, -1.9358, -0.0183,  0.6131],\n",
      "        [ 0.6917,  0.3086, -0.1792, -0.6363,  0.1763],\n",
      "        [-0.3763, -1.0822,  0.4990, -0.3132, -0.5449]], requires_grad=True)\n",
      "tensor([2, 3, 1])\n",
      "torch.Size([3, 5])\n",
      "tensor(2.9698, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example of target with class indices\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(target)\n",
    "print(input.shape)\n",
    "output = loss(input, target)\n",
    "print(output)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1611,  0.9480, -1.8485,  0.7824, -0.4267],\n",
      "        [-0.8531,  0.5648,  0.0154,  0.7545,  1.4698],\n",
      "        [-0.8237, -1.5654, -2.0004,  0.3435,  0.4356]], requires_grad=True)\n",
      "tensor([[0.1353, 0.1906, 0.1360, 0.1491, 0.3890],\n",
      "        [0.2017, 0.0178, 0.0122, 0.1175, 0.6508],\n",
      "        [0.1893, 0.6183, 0.0406, 0.1294, 0.0224]])\n",
      "tensor(1.9688, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Example of target with class probabilities\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "print(output)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "loss = nn.NLLLoss()\n",
    "# input is of size N x C = 3 x 5\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "# each element in target has to have 0 <= value < C\n",
    "target = torch.tensor([1, 0, 4])\n",
    "out = m(input)\n",
    "output = loss(m(input), target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3907, 0.5070, 0.1023],\n",
       "        [0.0866, 0.8850, 0.0284],\n",
       "        [0.2338, 0.3463, 0.4199],\n",
       "        [0.7409, 0.0561, 0.2030],\n",
       "        [0.5082, 0.0915, 0.4003],\n",
       "        [0.2424, 0.2539, 0.5037],\n",
       "        [0.4097, 0.3765, 0.2138],\n",
       "        [0.3312, 0.4499, 0.2189],\n",
       "        [0.4928, 0.2894, 0.2178],\n",
       "        [0.0989, 0.4751, 0.4259],\n",
       "        [0.7265, 0.1182, 0.1554],\n",
       "        [0.6221, 0.2868, 0.0911],\n",
       "        [0.2839, 0.1797, 0.5364],\n",
       "        [0.3021, 0.4534, 0.2445],\n",
       "        [0.1575, 0.3563, 0.4862],\n",
       "        [0.1050, 0.6420, 0.2530],\n",
       "        [0.2559, 0.7121, 0.0319],\n",
       "        [0.1789, 0.1610, 0.6601],\n",
       "        [0.9198, 0.0626, 0.0177],\n",
       "        [0.3374, 0.2002, 0.4623]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(20, 3)\n",
    "output = m(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = output.amax(axis=1)\n",
    "out[out>0.7]\n",
    "out[np.nonzero(out > 0.7)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available')\n",
    "else:\n",
    "    print('CUDA is available')\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Parameters for this experiment\"\"\"\n",
    "# params for loading the data\n",
    "path = 'data/Paderborn_FD/'\n",
    "source_domain = 'a'\n",
    "target_domains = ['b', 'c', 'd']\n",
    "best_accuracies = {'a': 0, 'b': 0, 'c': 0, 'd': 0}\n",
    "\n",
    "# params for configuring the model\n",
    "input_dim = 1\n",
    "hidden_dim = 256\n",
    "output_dim = 3\n",
    "drop_prob = 0.5\n",
    "\n",
    "# params for training the model\n",
    "epochs_pre = 20 # pre-training\n",
    "epochs = 20\n",
    "\n",
    "# optimizing the model\n",
    "lr = 1e-4\n",
    "d_lr = 1e-4\n",
    "batch_size = 20\n",
    "beta1 = 0.5\n",
    "beta2 = 0.9\n",
    "lambda_rpy = 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1, 5120)\n"
     ]
    }
   ],
   "source": [
    "# source domain data for training, validating and testing\n",
    "train_dataloader_src, val_dataloader_src, test_dataloader_src = generate_dataloaders(path, source_domain, batch_size)\n",
    "\n",
    "# target domain data for validating and testing\n",
    "train_dataloader_tgt, val_dataloader_tgt, test_dataloader_tgt = [], [], []\n",
    "for target_domain in target_domains:\n",
    "    train_dataloader_temp, val_dataloader_temp, test_dataloader_temp = generate_dataloaders(path, target_domain, batch_size)\n",
    "    \n",
    "    train_dataloader_tgt.append(train_dataloader_temp)\n",
    "    val_dataloader_tgt.append(val_dataloader_temp)\n",
    "    test_dataloader_tgt.append(test_dataloader_temp)\n",
    "\n",
    "# replay data for CDA\n",
    "replay_dataset = ReplayDataset(train_dataloader_src.dataset)\n",
    "replay_dataloader = DataLoader(dataset=replay_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_src = Encoder_AMDA(\n",
    "    input_dim=input_dim, # 1D input (sensor readings)\n",
    "    hidden_dim=hidden_dim # hidden layers 64\n",
    ")\n",
    "\n",
    "classifier = Classifier_AMDA(\n",
    "    hidden_dim=hidden_dim, # hidden layers 64\n",
    "    output_dim=output_dim, # 3 classes (healthy, inner- and outer-bearing damages)\n",
    "    dropout=drop_prob # dropout prob 0.5\n",
    ")\n",
    "\n",
    "encoder_tgt = Encoder_AMDA(\n",
    "    input_dim=input_dim, # 1D input (sensor readings)\n",
    "    hidden_dim=hidden_dim, # hidden layers 64\n",
    ")\n",
    "\n",
    "discriminator = Discriminator(\n",
    "    hidden_dim=hidden_dim\n",
    ")\n",
    "\n",
    "if train_on_gpu:\n",
    "    encoder_src = encoder_src.to(device)\n",
    "    classifier = classifier.to(device)\n",
    "    encoder_tgt = encoder_tgt.to(device)\n",
    "    discriminator = discriminator.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for training source encoder and shared classifier\n",
    "def train_src(encoder, classifier):\n",
    "    \"\"\"Train the source encoder and shared classifier on source domain\"\"\"\n",
    "    encoder.train()\n",
    "    classifier.train()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(\n",
    "        list(encoder.parameters()) + list(classifier.parameters()),\n",
    "        lr=lr,\n",
    "        betas=(beta1, beta2)\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs_pre):\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "\n",
    "        for batch_idx, (x_src, y_src) in enumerate(train_dataloader_src):\n",
    "            if train_on_gpu:\n",
    "                x_src, y_src = x_src.to(device), y_src.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            e_src = encoder(x_src)\n",
    "            # print(e_src.shape)\n",
    "            # print(e_src)\n",
    "            pred_src = classifier(e_src)\n",
    "            # print(pred_src)\n",
    "            # print(y_src)\n",
    "            loss_src = criterion(pred_src, y_src)\n",
    "            loss_src.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss_src.detach().item()) # detach the loss from compute graph\n",
    "            # print('1')\n",
    "            # print(y_src)\n",
    "            # print('2')\n",
    "            # print(pred_src.detach().argmax(dim=1))\n",
    "            # print('3')\n",
    "            # print(y_src.eq(pred_src.detach().argmax(dim=1)))\n",
    "            # print('4')\n",
    "            # print(y_src.eq(pred_src.detach().argmax(dim=1)).float())\n",
    "            # print('5')\n",
    "            # print(y_src.eq(pred_src.detach().argmax(dim=1)).float().mean())\n",
    "            accuracies.append(y_src.eq(pred_src.detach().argmax(dim=1)).float().mean())\n",
    "        \n",
    "        # print for each epoch\n",
    "        print(f'Epoch: {epoch + 1} \\n \\t Train Loss:{torch.tensor(losses).mean():0.2f} \\t Train Acc:{torch.tensor(accuracies).mean():0.2f}')\n",
    "\n",
    "        # for each epoch, evaluate your model on the validation data\n",
    "        val_loss, val_acc = evaluate_src(encoder, classifier, phase = 'Val')\n",
    "        print(f'\\t Val Loss:{val_loss:0.2f} \\t\\t Val Acc:{val_acc:0.2f}')\n",
    "\n",
    "    return encoder, classifier\n",
    "\n",
    "def evaluate_src(encoder, classifier, phase='Val'): # phase can be validate or test\n",
    "    \"\"\"Evaluate the trained network on source domain\"\"\"\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    dataloader = val_dataloader_src if phase == 'Val' else test_dataloader_src\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x_src, y_src) in enumerate(dataloader):\n",
    "            if train_on_gpu:\n",
    "                x_src, y_src = x_src.to(device), y_src.to(device)\n",
    "\n",
    "            e_src = encoder(x_src)\n",
    "            pred_src = classifier(e_src)\n",
    "            loss_src = criterion(pred_src, y_src)\n",
    "            \n",
    "            # append loss for each batch\n",
    "            losses.append(loss_src.detach().item()) # detach the loss from compute graph \n",
    "            accuracies.append(y_src.eq(pred_src.detach().argmax(dim=1)).float().mean())\n",
    "  \n",
    "        mean_loss = torch.tensor(losses).mean()\n",
    "        mean_acc = torch.tensor(accuracies).mean()\n",
    "        if dataloader == test_dataloader_src:\n",
    "            best_accuracies[source_domain] = max(best_accuracies[source_domain], mean_acc)\n",
    "        return mean_loss, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous Unsupervised Adaptation (CUA)\n",
    "# functions for training target encoder\n",
    "def train_tgt(encoder_src, encoder_tgt, classifier, discriminator, phase):\n",
    "    \"\"\"Train the target encoder on target domains with source encoder and test the network\"\"\"\n",
    "    encoder_tgt.train()\n",
    "    discriminator.train()\n",
    "    classifier.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(\n",
    "        encoder_tgt.parameters(),\n",
    "        lr=lr,\n",
    "        betas=(beta1, beta2)\n",
    "    )\n",
    "    d_optimizer = Adam(\n",
    "        discriminator.parameters(),\n",
    "        lr=d_lr,\n",
    "        betas=(beta1, beta2)\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        losses_d = []\n",
    "        losses_tgt = []\n",
    "        losses_rpy = []\n",
    "        accuracies = []\n",
    "        accuracies_d = []\n",
    "\n",
    "        for batch_idx, ((x_src, y_src), (x_tgt, y_tgt), (x_rpy, y_rpy)) in enumerate(zip(train_dataloader_src, train_dataloader_tgt[phase], replay_dataloader)):\n",
    "            if(train_on_gpu):\n",
    "                x_src, y_src = x_src.to(device), y_src.to(device)\n",
    "                x_tgt, y_tgt = x_tgt.to(device), y_tgt.to(device)\n",
    "                x_rpy, y_rpy = x_rpy.to(device), y_rpy.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            # part 1: sequential unsupervised adaptation\n",
    "            # learn e_src and _tgt: source and target mapping represenations\n",
    "            e_src = encoder_src(x_src)\n",
    "            e_tgt = encoder_tgt(x_tgt)\n",
    "            e_concat = torch.concat((e_src.detach(), e_tgt.detach()), 0)\n",
    "            # minimize distance between source and target empirical mapping distribution using adversarial discriminator\n",
    "            d_concat = discriminator(e_concat)\n",
    "\n",
    "            label_src = Variable(torch.ones(e_src.size(0)).long()).to(device)\n",
    "            label_tgt = Variable(torch.zeros(e_tgt.size(0)).long()).to(device)\n",
    "            label_concat = torch.cat((label_src, label_tgt), 0)\n",
    "\n",
    "            loss_d = criterion(d_concat, label_concat)\n",
    "            loss_d.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            e_tgt = encoder_tgt(x_tgt)\n",
    "            pred_tgt = classifier(e_tgt)\n",
    "            d_tgt = discriminator(e_tgt)\n",
    "            label_tgt = Variable(torch.ones(e_tgt.size(0)).long()).to(device)\n",
    "            loss_tgt = criterion(d_tgt, label_tgt)\n",
    "\n",
    "            # part 2: continuous replay adaptation\n",
    "            # additional replay loss to retain 'prior knowledge'\n",
    "            pred_rpy = classifier(encoder_tgt(x_rpy))\n",
    "            loss_rpy = criterion(pred_rpy, y_rpy)\n",
    "            loss = loss_tgt + lambda_rpy * loss_rpy\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # training (with replay) losses and accuracies\n",
    "            losses.append(loss.detach().item()) # detach the loss from compute graph\n",
    "            losses_d.append(loss_d.detach().item())\n",
    "            losses_tgt.append(loss_tgt.detach().item())\n",
    "            losses_rpy.append(loss_rpy.detach().item())\n",
    "            accuracies.append(y_tgt.eq(pred_tgt.detach().argmax(dim=1)).float().mean())\n",
    "            accuracies_d.append(torch.squeeze(d_concat.max(1)[1]).eq(label_concat.detach()).float().mean())\n",
    "        \n",
    "        # print for each epoch\n",
    "        print(f'Epoch: {epoch + 1} \\n \\t Train Loss:{torch.tensor(losses).mean():0.2f} \\t Train Acc:{torch.tensor(accuracies).mean():0.2f}')\n",
    "        print(f'\\t Discriminator Loss:{torch.tensor(losses_d).mean():0.2f} \\t Train (Replay) Loss:{torch.tensor(losses_rpy).mean():0.2f} \\t Train (Adversarial) Loss:{torch.tensor(losses_tgt).mean():0.2f}')\n",
    "        \n",
    "        # for each epoch, evaluate your model on the validation data\n",
    "        val_loss, val_acc = evaluate_tgt(encoder_tgt, classifier, val_dataloader_tgt[phase])\n",
    "        print(f'\\t Val (with Target) Loss:{val_loss:0.2f} \\t Val (with Target) Acc:{val_acc:0.2f}')\n",
    "\n",
    "    return encoder_tgt\n",
    "    \n",
    "# testing model on target domains\n",
    "\n",
    "def evaluate_tgt(encoder, classifier, dataloader):\n",
    "    \"\"\"Evaluate the network on current target domain\"\"\"\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, y) in enumerate(dataloader): # target dataloader\n",
    "            if(train_on_gpu):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "            pred_tgt = classifier(encoder(x))\n",
    "            loss_tgt = criterion(pred_tgt, y)\n",
    "            \n",
    "            # append loss for each batch\n",
    "            losses.append(loss_tgt.detach().item()) # detach the loss from compute graph \n",
    "            accuracies.append(y.eq(pred_tgt.detach().argmax(dim=1)).float().mean())\n",
    "            \n",
    "        mean_loss = torch.tensor(losses).mean()\n",
    "        mean_acc = torch.tensor(accuracies).mean()\n",
    "        if dataloader in test_dataloader_tgt:\n",
    "            index = test_dataloader_tgt.index(dataloader)\n",
    "            best_accuracies[target_domains[index]] = max(best_accuracies[target_domains[index]], mean_acc)\n",
    "\n",
    "        return mean_loss, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample previously seen examples and their respective classification scores as 'soft labels' from the target domains\n",
    "def generate_data_tuple(encoder_tgt, classifier, dataloader):\n",
    "    print('===> generate new replay dataset!')\n",
    "    encoder_tgt.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    m = nn.Softmax(dim=1)\n",
    "\n",
    "    all_x, all_pred = [], []\n",
    "    accuracies = []\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x_tgt, y_tgt) in enumerate(dataloader):\n",
    "            if(train_on_gpu):\n",
    "                x_tgt, y_tgt = x_tgt.to(device), y_tgt.to(device)\n",
    "\n",
    "            # perform classification with the target mapping representations\n",
    "            pred_tgt = classifier(encoder_tgt(x_tgt))\n",
    "            pred_tgt_softmax = m(pred_tgt)\n",
    "            confidence_level = pred_tgt_softmax.amax(axis=1)\n",
    "            # print(confidence_level)\n",
    "            # print(np.nonzero(confidence_level > 0.9))\n",
    "            # print(x_tgt)\n",
    "            # print(x_tgt.shape)\n",
    "            # print(torch.squeeze(x_tgt[np.nonzero(confidence_level > 0.9)], 1))\n",
    "            # print(torch.squeeze(x_tgt[np.nonzero(confidence_level > 0.9)], 1).shape)\n",
    "            # print(pred_tgt.detach().argmax(dim=1).shape)\n",
    "            # print(torch.squeeze(pred_tgt.detach().argmax(dim=1)[np.nonzero(confidence_level > 0.9)], 1))\n",
    "            # print(torch.squeeze(pred_tgt.detach().argmax(dim=1)[np.nonzero(confidence_level > 0.9)], 1).shape)\n",
    "            # print(y_tgt[np.nonzero(confidence_level > 0.9)])\n",
    "            # print(torch.squeeze(pred_tgt.detach().argmax(dim=1)[np.nonzero(confidence_level > 0.9)], 0))\n",
    "            # print(y_tgt[np.nonzero(confidence_level > 0.9)].eq(torch.squeeze(pred_tgt.detach().argmax(dim=1)[np.nonzero(confidence_level > 0.9)], 0)))\n",
    "            all_x.append(to_np(torch.squeeze(x_tgt[np.nonzero(confidence_level > 0.9)], 1)))\n",
    "            all_pred.append(to_np(torch.squeeze(pred_tgt.detach().argmax(dim=1)[np.nonzero(confidence_level > 0.9)], 1)))\n",
    "            accuracies.append(y_tgt[np.nonzero(confidence_level > 0.9)].eq(torch.squeeze(pred_tgt.detach().argmax(dim=1)[np.nonzero(confidence_level > 0.9)], 0)).float().mean())\n",
    "            \n",
    "        x, pred = np.concatenate(all_x, 0), np.concatenate(all_pred, 0)\n",
    "        num_samples = x.shape[0]\n",
    "        num_subsamples = int(0.1 * num_samples) # 0.1\n",
    "        np.random.seed(4154)\n",
    "        perm = np.random.permutation(num_samples)\n",
    "        x, pred = x[perm[0:num_subsamples]], pred[perm[0:num_subsamples]]\n",
    "\n",
    "        print('generated: ', x.shape, pred.shape, 'accuracy: ', torch.tensor(accuracies).mean())\n",
    "        return x, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-training\n",
    "# encoder_src, classifier = train_src(encoder_src, classifier)\n",
    "# torch.save(encoder_src.state_dict(), './dump/source_encoder.pt')\n",
    "# torch.save(classifier.state_dict(), './dump/classifier.pt')\n",
    "encoder_src.load_state_dict(torch.load('./dump/source_encoder.pt'))\n",
    "classifier.load_state_dict(torch.load('./dump/classifier.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 1 (Domain a to Domain b)\n",
      "Epoch: 1 \n",
      " \t Train Loss:1.15 \t Train Acc:0.37\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.88 \t Train (Adversarial) Loss:1.12\n",
      "\t Val (with Target) Loss:20.97 \t Val (with Target) Acc:0.41\n",
      "Epoch: 2 \n",
      " \t Train Loss:0.98 \t Train Acc:0.57\n",
      "\t Discriminator Loss:0.57 \t Train (Replay) Loss:1.35 \t Train (Adversarial) Loss:0.94\n",
      "\t Val (with Target) Loss:3.74 \t Val (with Target) Acc:0.72\n",
      "Epoch: 3 \n",
      " \t Train Loss:0.84 \t Train Acc:0.65\n",
      "\t Discriminator Loss:0.63 \t Train (Replay) Loss:0.81 \t Train (Adversarial) Loss:0.81\n",
      "\t Val (with Target) Loss:3.09 \t Val (with Target) Acc:0.66\n",
      "Epoch: 4 \n",
      " \t Train Loss:0.74 \t Train Acc:0.68\n",
      "\t Discriminator Loss:0.63 \t Train (Replay) Loss:0.68 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:2.82 \t Val (with Target) Acc:0.73\n",
      "Epoch: 5 \n",
      " \t Train Loss:0.70 \t Train Acc:0.68\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:0.43 \t Train (Adversarial) Loss:0.69\n",
      "\t Val (with Target) Loss:3.98 \t Val (with Target) Acc:0.65\n",
      "Epoch: 6 \n",
      " \t Train Loss:0.69 \t Train Acc:0.64\n",
      "\t Discriminator Loss:0.63 \t Train (Replay) Loss:0.26 \t Train (Adversarial) Loss:0.68\n",
      "\t Val (with Target) Loss:2.94 \t Val (with Target) Acc:0.70\n",
      "Epoch: 7 \n",
      " \t Train Loss:0.72 \t Train Acc:0.66\n",
      "\t Discriminator Loss:0.63 \t Train (Replay) Loss:0.26 \t Train (Adversarial) Loss:0.71\n",
      "\t Val (with Target) Loss:4.90 \t Val (with Target) Acc:0.60\n",
      "Epoch: 8 \n",
      " \t Train Loss:0.72 \t Train Acc:0.68\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.26 \t Train (Adversarial) Loss:0.71\n",
      "\t Val (with Target) Loss:2.70 \t Val (with Target) Acc:0.72\n",
      "Epoch: 9 \n",
      " \t Train Loss:0.76 \t Train Acc:0.69\n",
      "\t Discriminator Loss:0.61 \t Train (Replay) Loss:0.27 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:2.43 \t Val (with Target) Acc:0.74\n",
      "Epoch: 10 \n",
      " \t Train Loss:0.75 \t Train Acc:0.68\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:10.66 \t Val (with Target) Acc:0.44\n",
      "Epoch: 11 \n",
      " \t Train Loss:0.75 \t Train Acc:0.68\n",
      "\t Discriminator Loss:0.63 \t Train (Replay) Loss:0.24 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:2.09 \t Val (with Target) Acc:0.68\n",
      "Epoch: 12 \n",
      " \t Train Loss:0.77 \t Train Acc:0.67\n",
      "\t Discriminator Loss:0.61 \t Train (Replay) Loss:0.24 \t Train (Adversarial) Loss:0.76\n",
      "\t Val (with Target) Loss:2.83 \t Val (with Target) Acc:0.72\n",
      "Epoch: 13 \n",
      " \t Train Loss:0.80 \t Train Acc:0.65\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.23 \t Train (Adversarial) Loss:0.79\n",
      "\t Val (with Target) Loss:1.83 \t Val (with Target) Acc:0.74\n",
      "Epoch: 14 \n",
      " \t Train Loss:0.80 \t Train Acc:0.69\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.39 \t Train (Adversarial) Loss:0.79\n",
      "\t Val (with Target) Loss:4.56 \t Val (with Target) Acc:0.64\n",
      "Epoch: 15 \n",
      " \t Train Loss:0.83 \t Train Acc:0.66\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.45 \t Train (Adversarial) Loss:0.82\n",
      "\t Val (with Target) Loss:3.24 \t Val (with Target) Acc:0.73\n",
      "Epoch: 16 \n",
      " \t Train Loss:0.81 \t Train Acc:0.71\n",
      "\t Discriminator Loss:0.61 \t Train (Replay) Loss:0.40 \t Train (Adversarial) Loss:0.80\n",
      "\t Val (with Target) Loss:2.74 \t Val (with Target) Acc:0.70\n",
      "Epoch: 17 \n",
      " \t Train Loss:0.81 \t Train Acc:0.63\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.19 \t Train (Adversarial) Loss:0.80\n",
      "\t Val (with Target) Loss:3.16 \t Val (with Target) Acc:0.72\n",
      "Epoch: 18 \n",
      " \t Train Loss:0.88 \t Train Acc:0.65\n",
      "\t Discriminator Loss:0.59 \t Train (Replay) Loss:0.32 \t Train (Adversarial) Loss:0.87\n",
      "\t Val (with Target) Loss:1.98 \t Val (with Target) Acc:0.75\n",
      "Epoch: 19 \n",
      " \t Train Loss:0.87 \t Train Acc:0.73\n",
      "\t Discriminator Loss:0.59 \t Train (Replay) Loss:0.57 \t Train (Adversarial) Loss:0.85\n",
      "\t Val (with Target) Loss:3.04 \t Val (with Target) Acc:0.74\n",
      "Epoch: 20 \n",
      " \t Train Loss:0.84 \t Train Acc:0.75\n",
      "\t Discriminator Loss:0.59 \t Train (Replay) Loss:0.20 \t Train (Adversarial) Loss:0.83\n",
      "\t Val (with Target) Loss:2.12 \t Val (with Target) Acc:0.76\n",
      "\n",
      "Testing Accuracy on Previously Seen and Current Domains:\n",
      "Source Domain a:\n",
      "\t Test (with Source) Loss:0.37 \t Test (with Source) Acc:0.80\n",
      "Target Domain b:\n",
      "\t Test (with Target) Loss:2.03 \t Test (with Target) Acc:0.74\n",
      "===> generate new replay dataset!\n",
      "generated:  (787, 1, 5120) (787,) accuracy:  tensor(0.7650)\n",
      "1587\n",
      "\n",
      "Phase 2 (Domain b to Domain c)\n",
      "Epoch: 1 \n",
      " \t Train Loss:0.82 \t Train Acc:0.76\n",
      "\t Discriminator Loss:0.59 \t Train (Replay) Loss:0.38 \t Train (Adversarial) Loss:0.81\n",
      "\t Val (with Target) Loss:3.24 \t Val (with Target) Acc:0.77\n",
      "Epoch: 2 \n",
      " \t Train Loss:0.86 \t Train Acc:0.77\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.53 \t Train (Adversarial) Loss:0.85\n",
      "\t Val (with Target) Loss:3.73 \t Val (with Target) Acc:0.74\n",
      "Epoch: 3 \n",
      " \t Train Loss:0.91 \t Train Acc:0.76\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.49 \t Train (Adversarial) Loss:0.89\n",
      "\t Val (with Target) Loss:3.83 \t Val (with Target) Acc:0.76\n",
      "Epoch: 4 \n",
      " \t Train Loss:0.92 \t Train Acc:0.76\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.56 \t Train (Adversarial) Loss:0.91\n",
      "\t Val (with Target) Loss:4.30 \t Val (with Target) Acc:0.74\n",
      "Epoch: 5 \n",
      " \t Train Loss:0.93 \t Train Acc:0.75\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.46 \t Train (Adversarial) Loss:0.91\n",
      "\t Val (with Target) Loss:3.02 \t Val (with Target) Acc:0.77\n",
      "Epoch: 6 \n",
      " \t Train Loss:0.92 \t Train Acc:0.77\n",
      "\t Discriminator Loss:0.61 \t Train (Replay) Loss:0.43 \t Train (Adversarial) Loss:0.90\n",
      "\t Val (with Target) Loss:3.83 \t Val (with Target) Acc:0.76\n",
      "Epoch: 7 \n",
      " \t Train Loss:0.93 \t Train Acc:0.73\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.42 \t Train (Adversarial) Loss:0.92\n",
      "\t Val (with Target) Loss:3.56 \t Val (with Target) Acc:0.77\n",
      "Epoch: 8 \n",
      " \t Train Loss:0.92 \t Train Acc:0.75\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.43 \t Train (Adversarial) Loss:0.91\n",
      "\t Val (with Target) Loss:3.89 \t Val (with Target) Acc:0.76\n",
      "Epoch: 9 \n",
      " \t Train Loss:0.92 \t Train Acc:0.76\n",
      "\t Discriminator Loss:0.61 \t Train (Replay) Loss:0.41 \t Train (Adversarial) Loss:0.91\n",
      "\t Val (with Target) Loss:4.33 \t Val (with Target) Acc:0.75\n",
      "Epoch: 10 \n",
      " \t Train Loss:0.94 \t Train Acc:0.75\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:1.26 \t Train (Adversarial) Loss:0.90\n",
      "\t Val (with Target) Loss:3.40 \t Val (with Target) Acc:0.73\n",
      "Epoch: 11 \n",
      " \t Train Loss:0.94 \t Train Acc:0.79\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:2.71 \t Train (Adversarial) Loss:0.86\n",
      "\t Val (with Target) Loss:3.81 \t Val (with Target) Acc:0.75\n",
      "Epoch: 12 \n",
      " \t Train Loss:0.93 \t Train Acc:0.73\n",
      "\t Discriminator Loss:0.61 \t Train (Replay) Loss:0.38 \t Train (Adversarial) Loss:0.92\n",
      "\t Val (with Target) Loss:3.86 \t Val (with Target) Acc:0.76\n",
      "Epoch: 13 \n",
      " \t Train Loss:0.95 \t Train Acc:0.77\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:0.55 \t Train (Adversarial) Loss:0.94\n",
      "\t Val (with Target) Loss:3.19 \t Val (with Target) Acc:0.77\n",
      "Epoch: 14 \n",
      " \t Train Loss:0.95 \t Train Acc:0.79\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:1.60 \t Train (Adversarial) Loss:0.90\n",
      "\t Val (with Target) Loss:4.19 \t Val (with Target) Acc:0.76\n",
      "Epoch: 15 \n",
      " \t Train Loss:0.94 \t Train Acc:0.75\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.36 \t Train (Adversarial) Loss:0.92\n",
      "\t Val (with Target) Loss:3.98 \t Val (with Target) Acc:0.76\n",
      "Epoch: 16 \n",
      " \t Train Loss:0.95 \t Train Acc:0.78\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.50 \t Train (Adversarial) Loss:0.93\n",
      "\t Val (with Target) Loss:3.96 \t Val (with Target) Acc:0.76\n",
      "Epoch: 17 \n",
      " \t Train Loss:0.93 \t Train Acc:0.78\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:1.64 \t Train (Adversarial) Loss:0.88\n",
      "\t Val (with Target) Loss:3.32 \t Val (with Target) Acc:0.80\n",
      "Epoch: 18 \n",
      " \t Train Loss:0.89 \t Train Acc:0.80\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:2.01 \t Train (Adversarial) Loss:0.83\n",
      "\t Val (with Target) Loss:4.21 \t Val (with Target) Acc:0.76\n",
      "Epoch: 19 \n",
      " \t Train Loss:0.92 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:2.95 \t Train (Adversarial) Loss:0.83\n",
      "\t Val (with Target) Loss:3.90 \t Val (with Target) Acc:0.77\n",
      "Epoch: 20 \n",
      " \t Train Loss:0.93 \t Train Acc:0.76\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:0.50 \t Train (Adversarial) Loss:0.91\n",
      "\t Val (with Target) Loss:4.14 \t Val (with Target) Acc:0.77\n",
      "\n",
      "Testing Accuracy on Previously Seen and Current Domains:\n",
      "Source Domain a:\n",
      "\t Test (with Source) Loss:0.24 \t Test (with Source) Acc:0.92\n",
      "Target Domain b:\n",
      "\t Test (with Target) Loss:5.24 \t Test (with Target) Acc:0.73\n",
      "Target Domain c:\n",
      "\t Test (with Target) Loss:4.59 \t Test (with Target) Acc:0.74\n",
      "===> generate new replay dataset!\n",
      "generated:  (808, 1, 5120) (808,) accuracy:  tensor(0.7616)\n",
      "2395\n",
      "\n",
      "Phase 3 (Domain c to Domain d)\n",
      "Epoch: 1 \n",
      " \t Train Loss:0.98 \t Train Acc:0.97\n",
      "\t Discriminator Loss:0.69 \t Train (Replay) Loss:4.19 \t Train (Adversarial) Loss:0.86\n",
      "\t Val (with Target) Loss:0.05 \t Val (with Target) Acc:0.99\n",
      "Epoch: 2 \n",
      " \t Train Loss:0.96 \t Train Acc:0.91\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:2.34 \t Train (Adversarial) Loss:0.89\n",
      "\t Val (with Target) Loss:0.04 \t Val (with Target) Acc:0.99\n",
      "Epoch: 3 \n",
      " \t Train Loss:0.90 \t Train Acc:0.97\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:3.01 \t Train (Adversarial) Loss:0.81\n",
      "\t Val (with Target) Loss:0.05 \t Val (with Target) Acc:0.99\n",
      "Epoch: 4 \n",
      " \t Train Loss:0.92 \t Train Acc:0.97\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:2.84 \t Train (Adversarial) Loss:0.83\n",
      "\t Val (with Target) Loss:0.87 \t Val (with Target) Acc:0.84\n",
      "Epoch: 5 \n",
      " \t Train Loss:0.93 \t Train Acc:0.93\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:1.81 \t Train (Adversarial) Loss:0.87\n",
      "\t Val (with Target) Loss:0.85 \t Val (with Target) Acc:0.83\n",
      "Epoch: 6 \n",
      " \t Train Loss:0.95 \t Train Acc:0.92\n",
      "\t Discriminator Loss:0.64 \t Train (Replay) Loss:1.62 \t Train (Adversarial) Loss:0.90\n",
      "\t Val (with Target) Loss:0.04 \t Val (with Target) Acc:0.99\n",
      "Epoch: 7 \n",
      " \t Train Loss:0.92 \t Train Acc:0.94\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:2.18 \t Train (Adversarial) Loss:0.85\n",
      "\t Val (with Target) Loss:0.03 \t Val (with Target) Acc:0.99\n",
      "Epoch: 8 \n",
      " \t Train Loss:0.92 \t Train Acc:0.98\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:2.36 \t Train (Adversarial) Loss:0.85\n",
      "\t Val (with Target) Loss:0.19 \t Val (with Target) Acc:0.96\n",
      "Epoch: 9 \n",
      " \t Train Loss:0.92 \t Train Acc:0.98\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:2.33 \t Train (Adversarial) Loss:0.85\n",
      "\t Val (with Target) Loss:0.07 \t Val (with Target) Acc:0.99\n",
      "Epoch: 10 \n",
      " \t Train Loss:0.92 \t Train Acc:0.98\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:2.52 \t Train (Adversarial) Loss:0.85\n",
      "\t Val (with Target) Loss:0.06 \t Val (with Target) Acc:0.99\n",
      "Epoch: 11 \n",
      " \t Train Loss:0.94 \t Train Acc:0.98\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:1.97 \t Train (Adversarial) Loss:0.88\n",
      "\t Val (with Target) Loss:0.78 \t Val (with Target) Acc:0.87\n",
      "Epoch: 12 \n",
      " \t Train Loss:0.92 \t Train Acc:0.98\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:2.10 \t Train (Adversarial) Loss:0.85\n",
      "\t Val (with Target) Loss:0.09 \t Val (with Target) Acc:0.98\n",
      "Epoch: 13 \n",
      " \t Train Loss:0.95 \t Train Acc:0.98\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:2.12 \t Train (Adversarial) Loss:0.88\n",
      "\t Val (with Target) Loss:0.08 \t Val (with Target) Acc:0.98\n",
      "Epoch: 14 \n",
      " \t Train Loss:0.93 \t Train Acc:0.98\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:2.17 \t Train (Adversarial) Loss:0.87\n",
      "\t Val (with Target) Loss:0.09 \t Val (with Target) Acc:0.98\n",
      "Epoch: 15 \n",
      " \t Train Loss:0.92 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:1.87 \t Train (Adversarial) Loss:0.87\n",
      "\t Val (with Target) Loss:0.11 \t Val (with Target) Acc:0.98\n",
      "Epoch: 16 \n",
      " \t Train Loss:0.93 \t Train Acc:0.98\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:1.97 \t Train (Adversarial) Loss:0.87\n",
      "\t Val (with Target) Loss:0.07 \t Val (with Target) Acc:0.98\n",
      "Epoch: 17 \n",
      " \t Train Loss:0.91 \t Train Acc:0.98\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:1.95 \t Train (Adversarial) Loss:0.85\n",
      "\t Val (with Target) Loss:0.07 \t Val (with Target) Acc:0.98\n",
      "Epoch: 18 \n",
      " \t Train Loss:0.92 \t Train Acc:0.98\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:2.06 \t Train (Adversarial) Loss:0.86\n",
      "\t Val (with Target) Loss:0.15 \t Val (with Target) Acc:0.97\n",
      "Epoch: 19 \n",
      " \t Train Loss:0.92 \t Train Acc:0.98\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:1.94 \t Train (Adversarial) Loss:0.86\n",
      "\t Val (with Target) Loss:0.03 \t Val (with Target) Acc:0.99\n",
      "Epoch: 20 \n",
      " \t Train Loss:0.92 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:2.03 \t Train (Adversarial) Loss:0.86\n",
      "\t Val (with Target) Loss:0.13 \t Val (with Target) Acc:0.97\n",
      "\n",
      "Testing Accuracy on Previously Seen and Current Domains:\n",
      "Source Domain a:\n",
      "\t Test (with Source) Loss:1.66 \t Test (with Source) Acc:0.66\n",
      "Target Domain b:\n",
      "\t Test (with Target) Loss:0.77 \t Test (with Target) Acc:0.94\n",
      "Target Domain c:\n",
      "\t Test (with Target) Loss:1.94 \t Test (with Target) Acc:0.80\n",
      "Target Domain d:\n",
      "\t Test (with Target) Loss:0.12 \t Test (with Target) Acc:0.98\n",
      "===> generate new replay dataset!\n",
      "generated:  (795, 1, 5120) (795,) accuracy:  tensor(0.9843)\n",
      "3190\n"
     ]
    }
   ],
   "source": [
    "encoder_tgt.load_state_dict(encoder_src.state_dict())\n",
    "\n",
    "# adaptation\n",
    "for phase in range(len(target_domains)):\n",
    "    if(phase == 0): # Domain A to B\n",
    "        print(f'\\nPhase {phase + 1} (Domain {source_domain} to Domain {target_domains[phase]})')\n",
    "    else: # Domain B to C, and Domain C to D\n",
    "        print(f'\\nPhase {phase + 1} (Domain {target_domains[phase - 1]} to Domain {target_domains[phase]})')\n",
    "    \n",
    "    encoder_tgt = train_tgt(encoder_src, encoder_tgt, classifier, discriminator, phase)\n",
    "    \n",
    "    print('\\nTesting Accuracy on Previously Seen and Current Domains:')\n",
    "    print(f'Source Domain {source_domain}:')\n",
    "    src_test_loss, src_test_acc = evaluate_src(encoder_tgt, classifier, phase='Test')\n",
    "    print(f'\\t Test (with Source) Loss:{src_test_loss:0.2f} \\t Test (with Source) Acc:{src_test_acc:0.2f}') \n",
    "    for p in range(phase + 1):\n",
    "        print(f'Target Domain {target_domains[p]}:')\n",
    "        tgt_test_loss, tgt_test_acc = evaluate_tgt(encoder_tgt, classifier, test_dataloader_tgt[p])\n",
    "        print(f'\\t Test (with Target) Loss:{tgt_test_loss:0.2f} \\t Test (with Target) Acc:{tgt_test_acc:0.2f}')\n",
    "        \n",
    "    # update replay data and dataloader\n",
    "    data_tuple = generate_data_tuple(encoder_tgt, classifier, train_dataloader_tgt[phase])\n",
    "    replay_dataset.replay_dataset.update(data_tuple)\n",
    "    print(replay_dataset.__len__())\n",
    "    replay_dataloader = DataLoader(dataset=replay_dataset, shuffle=True, batch_size=batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Test (with Source) Loss:1.66 \t Test (with Source) Acc:0.66\n",
      "\n",
      "Phase 1 (Domain a to Domain b)\n",
      "\t Test (with Target) Loss:0.77 \t Test (with Target) Acc:0.94\n",
      "\n",
      "Phase 2 (Domain b to Domain c)\n",
      "\t Test (with Target) Loss:1.93 \t Test (with Target) Acc:0.80\n",
      "\n",
      "Phase 3 (Domain c to Domain d)\n",
      "\t Test (with Target) Loss:0.12 \t Test (with Target) Acc:0.98\n"
     ]
    }
   ],
   "source": [
    "src_test_loss, src_test_acc = evaluate_src(encoder_tgt, classifier, phase='Test')\n",
    "print(f'\\t Test (with Source) Loss:{src_test_loss:0.2f} \\t Test (with Source) Acc:{src_test_acc:0.2f}') \n",
    "for phase in range(len(target_domains)):\n",
    "    if(phase == 0): # Domain A to B\n",
    "        print(f'\\nPhase {phase + 1} (Domain {source_domain} to Domain {target_domains[phase]})')\n",
    "    else: # Domain B to C, and Domain C to D\n",
    "        print(f'\\nPhase {phase + 1} (Domain {target_domains[phase - 1]} to Domain {target_domains[phase]})')\n",
    "    \n",
    "    tgt_test_loss, tgt_test_acc = evaluate_tgt(encoder_tgt, classifier, test_dataloader_tgt[phase])\n",
    "    print(f'\\t Test (with Target) Loss:{tgt_test_loss:0.2f} \\t Test (with Target) Acc:{tgt_test_acc:0.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': tensor(0.9215),\n",
       " 'b': tensor(0.9391),\n",
       " 'c': tensor(0.7962),\n",
       " 'd': tensor(0.9766)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n"
     ]
    }
   ],
   "source": [
    "print(f\"{best_accuracies['a']:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = list(best_accuracies.keys())\n",
    "accuracies = list(best_accuracies.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c34056f8b0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(domains, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('cda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1e22e9a36d2ff643870da04044e3ba6e20e322fec5858ad637bee34c459619d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
