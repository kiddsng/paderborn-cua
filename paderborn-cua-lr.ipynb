{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Unsupervised Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules and libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# functions to create datasets and models\n",
    "from data.data import *\n",
    "from models.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available')\n",
    "else:\n",
    "    print('CUDA is available')\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Parameters for this experiment\"\"\"\n",
    "# params for loading the data\n",
    "path = 'data/Paderborn_FD/'\n",
    "source_domain = 'a'\n",
    "target_domains = ['b', 'c', 'd']\n",
    "\n",
    "# params for configuring the model\n",
    "input_dim = 1\n",
    "hidden_dim = 256\n",
    "output_dim = 3\n",
    "drop_prob = 0.5\n",
    "\n",
    "# params for training the model\n",
    "epochs_pre = 50 # pre-training\n",
    "epochs = 50\n",
    "\n",
    "# optimizing the model\n",
    "lr = 1e-5\n",
    "d_lr = 1e-5\n",
    "batch_size = 20\n",
    "beta1 = 0.5\n",
    "beta2 = 0.9\n",
    "lambda_rpy = 0.025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source domain data for training, validating and testing\n",
    "train_dataloader_src, val_dataloader_src, test_dataloader_src = generate_dataloaders(path, source_domain, batch_size)\n",
    "\n",
    "# target domain data for validating and testing\n",
    "train_dataloader_tgt, val_dataloader_tgt, test_dataloader_tgt = [], [], []\n",
    "for target_domain in target_domains:\n",
    "    train_dataloader_temp, val_dataloader_temp, test_dataloader_temp = generate_dataloaders(path, target_domain, batch_size)\n",
    "    \n",
    "    train_dataloader_tgt.append(train_dataloader_temp)\n",
    "    val_dataloader_tgt.append(val_dataloader_temp)\n",
    "    test_dataloader_tgt.append(test_dataloader_temp)\n",
    "\n",
    "# replay data for CDA\n",
    "replay_dataset = ReplayDataset(train_dataloader_src.dataset)\n",
    "replay_dataloader = DataLoader(dataset=replay_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_src = Encoder_AMDA(\n",
    "    input_dim=input_dim, # 1D input (sensor readings)\n",
    "    hidden_dim=hidden_dim # hidden layers 64\n",
    ")\n",
    "\n",
    "classifier = Classifier_AMDA(\n",
    "    hidden_dim=hidden_dim, # hidden layers 64\n",
    "    output_dim=output_dim, # 3 classes (healthy, inner- and outer-bearing damages)\n",
    "    dropout=drop_prob # dropout prob 0.5\n",
    ")\n",
    "\n",
    "encoder_tgt = Encoder_AMDA(\n",
    "    input_dim=input_dim, # 1D input (sensor readings)\n",
    "    hidden_dim=hidden_dim, # hidden layers 64\n",
    ")\n",
    "\n",
    "discriminator = Discriminator(\n",
    "    hidden_dim=hidden_dim\n",
    ")\n",
    "\n",
    "if train_on_gpu:\n",
    "    encoder_src = encoder_src.to(device)\n",
    "    classifier = classifier.to(device)\n",
    "    encoder_tgt = encoder_tgt.to(device)\n",
    "    discriminator = discriminator.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for training source encoder and shared classifier\n",
    "def train_src(encoder, classifier):\n",
    "    \"\"\"Train the source encoder and shared classifier on source domain\"\"\"\n",
    "    encoder.train()\n",
    "    classifier.train()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(\n",
    "        list(encoder.parameters()) + list(classifier.parameters()),\n",
    "        lr=lr,\n",
    "        betas=(beta1, beta2)\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs_pre):\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "\n",
    "        for batch_idx, (x_src, y_src) in enumerate(train_dataloader_src):\n",
    "            if train_on_gpu:\n",
    "                x_src, y_src = x_src.to(device), y_src.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            e_src = encoder(x_src)\n",
    "            pred_src = classifier(e_src)\n",
    "            loss_src = criterion(pred_src, y_src)\n",
    "            loss_src.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss_src.detach().item()) # detach the loss from compute graph \n",
    "            accuracies.append(y_src.eq(pred_src.detach().argmax(dim=1)).float().mean())\n",
    "        \n",
    "        # print for each epoch\n",
    "        print(f'Epoch: {epoch + 1} \\n \\t Train Loss:{torch.tensor(losses).mean():0.2f} \\t Train Acc:{torch.tensor(accuracies).mean():0.2f}')\n",
    "\n",
    "        # for each epoch, evaluate your model on the validation data\n",
    "        val_loss, val_acc = evaluate_src(encoder, classifier, phase = 'Val')\n",
    "        print(f'\\t Val Loss:{val_loss:0.2f} \\t\\t Val Acc:{val_acc:0.2f}')\n",
    "\n",
    "    return encoder, classifier\n",
    "\n",
    "# testing model on source domain\n",
    "def evaluate_src(encoder, classifier, phase='Val'): # phase can be validate or test\n",
    "    \"\"\"Evaluate the trained network on source domain\"\"\"\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    dataloader = val_dataloader_src if phase == 'Val' else test_dataloader_src\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x_src, y_src) in enumerate(dataloader):\n",
    "            if train_on_gpu:\n",
    "                x_src, y_src = x_src.to(device), y_src.to(device)\n",
    "\n",
    "            e_src = encoder(x_src)\n",
    "            pred_src = classifier(e_src)\n",
    "            loss_src = criterion(pred_src, y_src)\n",
    "            \n",
    "            # append loss for each batch\n",
    "            losses.append(loss_src.detach().item()) # detach the loss from compute graph \n",
    "            accuracies.append(y_src.eq(pred_src.detach().argmax(dim=1)).float().mean())\n",
    "            \n",
    "        mean_loss = torch.tensor(losses).mean()\n",
    "        mean_acc = torch.tensor(accuracies).mean()\n",
    "        return mean_loss, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous Unsupervised Adaptation (CUA)\n",
    "# functions for training target encoder\n",
    "def train_tgt(encoder_src, encoder_tgt, classifier, discriminator, phase):\n",
    "    \"\"\"Train the target encoder on target domains with source encoder and test the network\"\"\"\n",
    "    encoder_tgt.train()\n",
    "    discriminator.train()\n",
    "    classifier.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(\n",
    "        encoder_tgt.parameters(),\n",
    "        lr=lr,\n",
    "        betas=(beta1, beta2)\n",
    "    )\n",
    "    d_optimizer = Adam(\n",
    "        discriminator.parameters(),\n",
    "        lr=d_lr,\n",
    "        betas=(beta1, beta2)\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        losses_d = []\n",
    "        losses_tgt = []\n",
    "        losses_rpy = []\n",
    "        accuracies = []\n",
    "\n",
    "        for batch_idx, ((x_src, y_src), (x_tgt, y_tgt), (x_rpy, y_rpy)) in enumerate(zip(train_dataloader_src, train_dataloader_tgt[phase], replay_dataloader)):\n",
    "            if(train_on_gpu):\n",
    "                x_src, y_src = x_src.to(device), y_src.to(device)\n",
    "                x_tgt, y_tgt = x_tgt.to(device), y_tgt.to(device)\n",
    "                x_rpy, y_rpy = x_rpy.to(device), y_rpy.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            # part 1: sequential unsupervised adaptation\n",
    "            # learn e_src and _tgt: source and target mapping represenations\n",
    "            e_src = encoder_src(x_src)\n",
    "            e_tgt = encoder_tgt(x_tgt)\n",
    "            e_concat = torch.concat((e_src.detach(), e_tgt.detach()), 0)\n",
    "            # minimize distance between source and target empirical mapping distribution using adversarial discriminator\n",
    "            d_concat = discriminator(e_concat)\n",
    "\n",
    "            label_src = Variable(torch.ones(e_src.size(0)).long()).to(device)\n",
    "            label_tgt = Variable(torch.zeros(e_tgt.size(0)).long()).to(device)\n",
    "            label_concat = torch.cat((label_src, label_tgt), 0)\n",
    "\n",
    "            loss_d = criterion(d_concat, label_concat)\n",
    "            loss_d.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            e_tgt = encoder_tgt(x_tgt)\n",
    "            pred_tgt = classifier(e_tgt)\n",
    "            d_tgt = discriminator(e_tgt)\n",
    "            label_tgt = Variable(torch.ones(e_tgt.size(0)).long()).to(device)\n",
    "            loss_tgt = criterion(d_tgt, label_tgt)\n",
    "\n",
    "            # part 2: continuous replay adaptation\n",
    "            # additional replay loss to retain 'prior knowledge'\n",
    "            pred_rpy = classifier(encoder_tgt(x_rpy))\n",
    "            loss_rpy = criterion(pred_rpy, y_rpy)\n",
    "            loss = loss_tgt + lambda_rpy * loss_rpy\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # training (with replay) losses and accuracies\n",
    "            losses.append(loss.detach().item()) # detach the loss from compute graph\n",
    "            losses_d.append(loss_d.detach().item())\n",
    "            losses_tgt.append(loss_tgt.detach().item())\n",
    "            losses_rpy.append(loss_rpy.detach().item())\n",
    "            accuracies.append(y_tgt.eq(pred_tgt.detach().argmax(dim=1)).float().mean())\n",
    "        \n",
    "        # print for each epoch\n",
    "        # print for each epoch\n",
    "        print(f'Epoch: {epoch + 1} \\n \\t Train Loss:{torch.tensor(losses).mean():0.2f} \\t Train Acc:{torch.tensor(accuracies).mean():0.2f}')\n",
    "        print(f'\\t Discriminator Loss:{torch.tensor(losses_d).mean():0.2f} \\t Train (Replay) Loss:{torch.tensor(losses_rpy).mean():0.2f} \\t Train (Adversarial) Loss:{torch.tensor(losses_tgt).mean():0.2f}')\n",
    "        \n",
    "        # for each epoch, evaluate your model on the validation data\n",
    "        val_loss, val_acc = evaluate_tgt(encoder_tgt, classifier, val_dataloader_tgt[phase])\n",
    "        print(f'\\t Val (with Target) Loss:{val_loss:0.2f} \\t Val (with Target) Acc:{val_acc:0.2f}')\n",
    "\n",
    "    return encoder_tgt\n",
    "    \n",
    "# testing model on target domains\n",
    "def evaluate_tgt(encoder, classifier, dataloader):\n",
    "    \"\"\"Evaluate the network on current target domain\"\"\"\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, y) in enumerate(dataloader): # target dataloader\n",
    "            if(train_on_gpu):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "            pred_tgt = classifier(encoder(x))\n",
    "            loss_tgt = criterion(pred_tgt, y)\n",
    "            \n",
    "            # append loss for each batch\n",
    "            losses.append(loss_tgt.detach().item()) # detach the loss from compute graph \n",
    "            accuracies.append(y.eq(pred_tgt.detach().argmax(dim=1)).float().mean())\n",
    "            \n",
    "        mean_loss = torch.tensor(losses).mean()\n",
    "        mean_acc = torch.tensor(accuracies).mean()\n",
    "        return mean_loss, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample previously seen examples and their respective classification scores as 'soft labels' from the target domains\n",
    "def generate_data_tuple(encoder_tgt, classifier, dataloader):\n",
    "    print('===> generate new replay dataset!')\n",
    "    encoder_tgt.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    all_x, all_pred = [], []\n",
    "    for batch_idx, (x_tgt, y_tgt) in enumerate(dataloader):\n",
    "        if(train_on_gpu):\n",
    "            x_tgt, y_tgt = x_tgt.to(device), y_tgt.to(device)\n",
    "\n",
    "        # perform classification with the target mapping representations\n",
    "        pred_tgt = classifier(encoder_tgt(x_tgt))\n",
    "\n",
    "        all_x.append(to_np(x_tgt))\n",
    "        all_pred.append(to_np(pred_tgt.detach().argmax(dim=1)))\n",
    "        \n",
    "    x, pred = np.concatenate(all_x, 0), np.concatenate(all_pred, 0)\n",
    "    print('generated: ', x.shape, pred.shape)\n",
    "    return x, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      " \t Train Loss:1.06 \t Train Acc:0.46\n",
      "\t Val Loss:1.03 \t\t Val Acc:0.45\n",
      "Epoch: 2 \n",
      " \t Train Loss:1.01 \t Train Acc:0.46\n",
      "\t Val Loss:0.98 \t\t Val Acc:0.45\n",
      "Epoch: 3 \n",
      " \t Train Loss:0.95 \t Train Acc:0.46\n",
      "\t Val Loss:0.93 \t\t Val Acc:0.45\n",
      "Epoch: 4 \n",
      " \t Train Loss:0.91 \t Train Acc:0.44\n",
      "\t Val Loss:0.89 \t\t Val Acc:0.45\n",
      "Epoch: 5 \n",
      " \t Train Loss:0.85 \t Train Acc:0.57\n",
      "\t Val Loss:0.79 \t\t Val Acc:0.60\n",
      "Epoch: 6 \n",
      " \t Train Loss:0.73 \t Train Acc:0.69\n",
      "\t Val Loss:0.66 \t\t Val Acc:0.75\n",
      "Epoch: 7 \n",
      " \t Train Loss:0.62 \t Train Acc:0.75\n",
      "\t Val Loss:0.58 \t\t Val Acc:0.76\n",
      "Epoch: 8 \n",
      " \t Train Loss:0.56 \t Train Acc:0.77\n",
      "\t Val Loss:0.53 \t\t Val Acc:0.78\n",
      "Epoch: 9 \n",
      " \t Train Loss:0.52 \t Train Acc:0.78\n",
      "\t Val Loss:0.50 \t\t Val Acc:0.79\n",
      "Epoch: 10 \n",
      " \t Train Loss:0.49 \t Train Acc:0.79\n",
      "\t Val Loss:0.47 \t\t Val Acc:0.80\n",
      "Epoch: 11 \n",
      " \t Train Loss:0.47 \t Train Acc:0.80\n",
      "\t Val Loss:0.46 \t\t Val Acc:0.80\n",
      "Epoch: 12 \n",
      " \t Train Loss:0.46 \t Train Acc:0.80\n",
      "\t Val Loss:0.44 \t\t Val Acc:0.81\n",
      "Epoch: 13 \n",
      " \t Train Loss:0.45 \t Train Acc:0.81\n",
      "\t Val Loss:0.43 \t\t Val Acc:0.81\n",
      "Epoch: 14 \n",
      " \t Train Loss:0.44 \t Train Acc:0.81\n",
      "\t Val Loss:0.42 \t\t Val Acc:0.81\n",
      "Epoch: 15 \n",
      " \t Train Loss:0.43 \t Train Acc:0.81\n",
      "\t Val Loss:0.42 \t\t Val Acc:0.81\n",
      "Epoch: 16 \n",
      " \t Train Loss:0.42 \t Train Acc:0.81\n",
      "\t Val Loss:0.41 \t\t Val Acc:0.81\n",
      "Epoch: 17 \n",
      " \t Train Loss:0.41 \t Train Acc:0.81\n",
      "\t Val Loss:0.40 \t\t Val Acc:0.81\n",
      "Epoch: 18 \n",
      " \t Train Loss:0.41 \t Train Acc:0.81\n",
      "\t Val Loss:0.40 \t\t Val Acc:0.81\n",
      "Epoch: 19 \n",
      " \t Train Loss:0.40 \t Train Acc:0.81\n",
      "\t Val Loss:0.39 \t\t Val Acc:0.81\n",
      "Epoch: 20 \n",
      " \t Train Loss:0.40 \t Train Acc:0.81\n",
      "\t Val Loss:0.39 \t\t Val Acc:0.81\n",
      "Epoch: 21 \n",
      " \t Train Loss:0.39 \t Train Acc:0.81\n",
      "\t Val Loss:0.38 \t\t Val Acc:0.81\n",
      "Epoch: 22 \n",
      " \t Train Loss:0.38 \t Train Acc:0.81\n",
      "\t Val Loss:0.37 \t\t Val Acc:0.81\n",
      "Epoch: 23 \n",
      " \t Train Loss:0.37 \t Train Acc:0.81\n",
      "\t Val Loss:0.36 \t\t Val Acc:0.81\n",
      "Epoch: 24 \n",
      " \t Train Loss:0.36 \t Train Acc:0.81\n",
      "\t Val Loss:0.35 \t\t Val Acc:0.81\n",
      "Epoch: 25 \n",
      " \t Train Loss:0.35 \t Train Acc:0.81\n",
      "\t Val Loss:0.34 \t\t Val Acc:0.81\n",
      "Epoch: 26 \n",
      " \t Train Loss:0.33 \t Train Acc:0.81\n",
      "\t Val Loss:0.32 \t\t Val Acc:0.82\n",
      "Epoch: 27 \n",
      " \t Train Loss:0.32 \t Train Acc:0.81\n",
      "\t Val Loss:0.31 \t\t Val Acc:0.82\n",
      "Epoch: 28 \n",
      " \t Train Loss:0.30 \t Train Acc:0.83\n",
      "\t Val Loss:0.29 \t\t Val Acc:0.84\n",
      "Epoch: 29 \n",
      " \t Train Loss:0.28 \t Train Acc:0.86\n",
      "\t Val Loss:0.27 \t\t Val Acc:0.87\n",
      "Epoch: 30 \n",
      " \t Train Loss:0.26 \t Train Acc:0.89\n",
      "\t Val Loss:0.25 \t\t Val Acc:0.90\n",
      "Epoch: 31 \n",
      " \t Train Loss:0.25 \t Train Acc:0.91\n",
      "\t Val Loss:0.24 \t\t Val Acc:0.92\n",
      "Epoch: 32 \n",
      " \t Train Loss:0.23 \t Train Acc:0.92\n",
      "\t Val Loss:0.22 \t\t Val Acc:0.93\n",
      "Epoch: 33 \n",
      " \t Train Loss:0.21 \t Train Acc:0.93\n",
      "\t Val Loss:0.20 \t\t Val Acc:0.94\n",
      "Epoch: 34 \n",
      " \t Train Loss:0.20 \t Train Acc:0.94\n",
      "\t Val Loss:0.19 \t\t Val Acc:0.94\n",
      "Epoch: 35 \n",
      " \t Train Loss:0.19 \t Train Acc:0.94\n",
      "\t Val Loss:0.18 \t\t Val Acc:0.94\n",
      "Epoch: 36 \n",
      " \t Train Loss:0.18 \t Train Acc:0.94\n",
      "\t Val Loss:0.17 \t\t Val Acc:0.95\n",
      "Epoch: 37 \n",
      " \t Train Loss:0.17 \t Train Acc:0.95\n",
      "\t Val Loss:0.16 \t\t Val Acc:0.95\n",
      "Epoch: 38 \n",
      " \t Train Loss:0.16 \t Train Acc:0.95\n",
      "\t Val Loss:0.15 \t\t Val Acc:0.95\n",
      "Epoch: 39 \n",
      " \t Train Loss:0.15 \t Train Acc:0.95\n",
      "\t Val Loss:0.14 \t\t Val Acc:0.95\n",
      "Epoch: 40 \n",
      " \t Train Loss:0.14 \t Train Acc:0.95\n",
      "\t Val Loss:0.14 \t\t Val Acc:0.95\n",
      "Epoch: 41 \n",
      " \t Train Loss:0.14 \t Train Acc:0.96\n",
      "\t Val Loss:0.13 \t\t Val Acc:0.96\n",
      "Epoch: 42 \n",
      " \t Train Loss:0.13 \t Train Acc:0.96\n",
      "\t Val Loss:0.13 \t\t Val Acc:0.96\n",
      "Epoch: 43 \n",
      " \t Train Loss:0.12 \t Train Acc:0.96\n",
      "\t Val Loss:0.12 \t\t Val Acc:0.96\n",
      "Epoch: 44 \n",
      " \t Train Loss:0.12 \t Train Acc:0.96\n",
      "\t Val Loss:0.11 \t\t Val Acc:0.96\n",
      "Epoch: 45 \n",
      " \t Train Loss:0.11 \t Train Acc:0.96\n",
      "\t Val Loss:0.11 \t\t Val Acc:0.96\n",
      "Epoch: 46 \n",
      " \t Train Loss:0.11 \t Train Acc:0.96\n",
      "\t Val Loss:0.11 \t\t Val Acc:0.96\n",
      "Epoch: 47 \n",
      " \t Train Loss:0.10 \t Train Acc:0.97\n",
      "\t Val Loss:0.10 \t\t Val Acc:0.96\n",
      "Epoch: 48 \n",
      " \t Train Loss:0.10 \t Train Acc:0.97\n",
      "\t Val Loss:0.10 \t\t Val Acc:0.96\n",
      "Epoch: 49 \n",
      " \t Train Loss:0.10 \t Train Acc:0.97\n",
      "\t Val Loss:0.09 \t\t Val Acc:0.97\n",
      "Epoch: 50 \n",
      " \t Train Loss:0.09 \t Train Acc:0.97\n",
      "\t Val Loss:0.09 \t\t Val Acc:0.97\n"
     ]
    }
   ],
   "source": [
    "# pre-training\n",
    "encoder_src, classifier = train_src(encoder_src, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 1 (Domain a to Domain b)\n",
      "Epoch: 1 \n",
      " \t Train Loss:1.11 \t Train Acc:0.53\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:3.27 \t Train (Adversarial) Loss:1.03\n",
      "\t Val (with Target) Loss:2.38 \t Val (with Target) Acc:0.75\n",
      "Epoch: 2 \n",
      " \t Train Loss:0.81 \t Train Acc:0.69\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:4.65 \t Train (Adversarial) Loss:0.70\n",
      "\t Val (with Target) Loss:1.03 \t Val (with Target) Acc:0.78\n",
      "Epoch: 3 \n",
      " \t Train Loss:0.78 \t Train Acc:0.70\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:3.34 \t Train (Adversarial) Loss:0.70\n",
      "\t Val (with Target) Loss:2.70 \t Val (with Target) Acc:0.59\n",
      "Epoch: 4 \n",
      " \t Train Loss:0.75 \t Train Acc:0.63\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:2.25 \t Train (Adversarial) Loss:0.70\n",
      "\t Val (with Target) Loss:2.24 \t Val (with Target) Acc:0.59\n",
      "Epoch: 5 \n",
      " \t Train Loss:0.73 \t Train Acc:0.67\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:1.99 \t Train (Adversarial) Loss:0.68\n",
      "\t Val (with Target) Loss:0.71 \t Val (with Target) Acc:0.82\n",
      "Epoch: 6 \n",
      " \t Train Loss:0.74 \t Train Acc:0.68\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:1.81 \t Train (Adversarial) Loss:0.69\n",
      "\t Val (with Target) Loss:0.88 \t Val (with Target) Acc:0.71\n",
      "Epoch: 7 \n",
      " \t Train Loss:0.76 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:2.03 \t Train (Adversarial) Loss:0.71\n",
      "\t Val (with Target) Loss:0.39 \t Val (with Target) Acc:0.89\n",
      "Epoch: 8 \n",
      " \t Train Loss:0.76 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:1.82 \t Train (Adversarial) Loss:0.71\n",
      "\t Val (with Target) Loss:0.36 \t Val (with Target) Acc:0.88\n",
      "Epoch: 9 \n",
      " \t Train Loss:0.77 \t Train Acc:0.89\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:1.74 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.39 \t Val (with Target) Acc:0.88\n",
      "Epoch: 10 \n",
      " \t Train Loss:0.79 \t Train Acc:0.90\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:1.59 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:0.57 \t Val (with Target) Acc:0.91\n",
      "Epoch: 11 \n",
      " \t Train Loss:0.78 \t Train Acc:0.91\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:1.56 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:0.42 \t Val (with Target) Acc:0.88\n",
      "Epoch: 12 \n",
      " \t Train Loss:0.79 \t Train Acc:0.89\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:1.53 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:0.45 \t Val (with Target) Acc:0.85\n",
      "Epoch: 13 \n",
      " \t Train Loss:0.78 \t Train Acc:0.88\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:1.52 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:0.40 \t Val (with Target) Acc:0.86\n",
      "Epoch: 14 \n",
      " \t Train Loss:0.77 \t Train Acc:0.89\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:1.50 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.43 \t Val (with Target) Acc:0.86\n",
      "Epoch: 15 \n",
      " \t Train Loss:0.77 \t Train Acc:0.89\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:1.46 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.51 \t Val (with Target) Acc:0.85\n",
      "Epoch: 16 \n",
      " \t Train Loss:0.76 \t Train Acc:0.87\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:1.28 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.56 \t Val (with Target) Acc:0.83\n",
      "Epoch: 17 \n",
      " \t Train Loss:0.76 \t Train Acc:0.88\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:1.27 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.42 \t Val (with Target) Acc:0.90\n",
      "Epoch: 18 \n",
      " \t Train Loss:0.76 \t Train Acc:0.89\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:1.18 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.45 \t Val (with Target) Acc:0.89\n",
      "Epoch: 19 \n",
      " \t Train Loss:0.76 \t Train Acc:0.88\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:1.16 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.55 \t Val (with Target) Acc:0.85\n",
      "Epoch: 20 \n",
      " \t Train Loss:0.77 \t Train Acc:0.88\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:1.06 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:0.49 \t Val (with Target) Acc:0.89\n",
      "Epoch: 21 \n",
      " \t Train Loss:0.77 \t Train Acc:0.89\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.97 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.50 \t Val (with Target) Acc:0.87\n",
      "Epoch: 22 \n",
      " \t Train Loss:0.77 \t Train Acc:0.88\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.95 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.86\n",
      "Epoch: 23 \n",
      " \t Train Loss:0.76 \t Train Acc:0.88\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.99 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.48 \t Val (with Target) Acc:0.87\n",
      "Epoch: 24 \n",
      " \t Train Loss:0.77 \t Train Acc:0.88\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.92 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:0.49 \t Val (with Target) Acc:0.86\n",
      "Epoch: 25 \n",
      " \t Train Loss:0.76 \t Train Acc:0.87\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.92 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.45 \t Val (with Target) Acc:0.87\n",
      "Epoch: 26 \n",
      " \t Train Loss:0.77 \t Train Acc:0.87\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.90 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.49 \t Val (with Target) Acc:0.88\n",
      "Epoch: 27 \n",
      " \t Train Loss:0.76 \t Train Acc:0.88\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.89 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.87\n",
      "Epoch: 28 \n",
      " \t Train Loss:0.76 \t Train Acc:0.88\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.83 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.43 \t Val (with Target) Acc:0.87\n",
      "Epoch: 29 \n",
      " \t Train Loss:0.76 \t Train Acc:0.88\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.78 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.47 \t Val (with Target) Acc:0.86\n",
      "Epoch: 30 \n",
      " \t Train Loss:0.76 \t Train Acc:0.88\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.77 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.88\n",
      "Epoch: 31 \n",
      " \t Train Loss:0.76 \t Train Acc:0.88\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.79 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.45 \t Val (with Target) Acc:0.86\n",
      "Epoch: 32 \n",
      " \t Train Loss:0.76 \t Train Acc:0.87\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.74 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.45 \t Val (with Target) Acc:0.87\n",
      "Epoch: 33 \n",
      " \t Train Loss:0.75 \t Train Acc:0.87\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.78 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.43 \t Val (with Target) Acc:0.86\n",
      "Epoch: 34 \n",
      " \t Train Loss:0.75 \t Train Acc:0.87\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.71 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.86\n",
      "Epoch: 35 \n",
      " \t Train Loss:0.75 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.69 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.45 \t Val (with Target) Acc:0.86\n",
      "Epoch: 36 \n",
      " \t Train Loss:0.76 \t Train Acc:0.87\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.70 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.38 \t Val (with Target) Acc:0.86\n",
      "Epoch: 37 \n",
      " \t Train Loss:0.75 \t Train Acc:0.87\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.70 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.40 \t Val (with Target) Acc:0.86\n",
      "Epoch: 38 \n",
      " \t Train Loss:0.75 \t Train Acc:0.87\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.68 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.40 \t Val (with Target) Acc:0.86\n",
      "Epoch: 39 \n",
      " \t Train Loss:0.74 \t Train Acc:0.87\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.74 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.40 \t Val (with Target) Acc:0.86\n",
      "Epoch: 40 \n",
      " \t Train Loss:0.75 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.68 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.39 \t Val (with Target) Acc:0.85\n",
      "Epoch: 41 \n",
      " \t Train Loss:0.75 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.68 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.43 \t Val (with Target) Acc:0.85\n",
      "Epoch: 42 \n",
      " \t Train Loss:0.74 \t Train Acc:0.85\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.67 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.40 \t Val (with Target) Acc:0.85\n",
      "Epoch: 43 \n",
      " \t Train Loss:0.75 \t Train Acc:0.85\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.63 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.83\n",
      "Epoch: 44 \n",
      " \t Train Loss:0.75 \t Train Acc:0.85\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.66 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.40 \t Val (with Target) Acc:0.85\n",
      "Epoch: 45 \n",
      " \t Train Loss:0.74 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.64 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.41 \t Val (with Target) Acc:0.84\n",
      "Epoch: 46 \n",
      " \t Train Loss:0.75 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.65 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.40 \t Val (with Target) Acc:0.84\n",
      "Epoch: 47 \n",
      " \t Train Loss:0.74 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.62 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.40 \t Val (with Target) Acc:0.84\n",
      "Epoch: 48 \n",
      " \t Train Loss:0.74 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.61 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.40 \t Val (with Target) Acc:0.84\n",
      "Epoch: 49 \n",
      " \t Train Loss:0.74 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.60 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.42 \t Val (with Target) Acc:0.84\n",
      "Epoch: 50 \n",
      " \t Train Loss:0.74 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.58 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.41 \t Val (with Target) Acc:0.83\n",
      "\n",
      "Testing Accuracy on Previously Seen and Current Domains:\n",
      "Source Domain a:\n",
      "\t Test (with Source) Loss:0.56 \t Test (with Source) Acc:0.72\n",
      "Target Domain b:\n",
      "\t Test (with Target) Loss:0.38 \t Test (with Target) Acc:0.83\n",
      "===> generate new replay dataset!\n",
      "generated:  (8184, 1, 5120) (8184,)\n",
      "16368\n",
      "\n",
      "Phase 2 (Domain b to Domain c)\n",
      "Epoch: 1 \n",
      " \t Train Loss:0.72 \t Train Acc:0.80\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:0.38 \t Train (Adversarial) Loss:0.71\n",
      "\t Val (with Target) Loss:0.82 \t Val (with Target) Acc:0.83\n",
      "Epoch: 2 \n",
      " \t Train Loss:0.71 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.37 \t Train (Adversarial) Loss:0.70\n",
      "\t Val (with Target) Loss:0.85 \t Val (with Target) Acc:0.83\n",
      "Epoch: 3 \n",
      " \t Train Loss:0.73 \t Train Acc:0.83\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.33 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.83 \t Val (with Target) Acc:0.84\n",
      "Epoch: 4 \n",
      " \t Train Loss:0.76 \t Train Acc:0.83\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.32 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:0.80 \t Val (with Target) Acc:0.84\n",
      "Epoch: 5 \n",
      " \t Train Loss:0.77 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.33 \t Train (Adversarial) Loss:0.76\n",
      "\t Val (with Target) Loss:0.77 \t Val (with Target) Acc:0.85\n",
      "Epoch: 6 \n",
      " \t Train Loss:0.78 \t Train Acc:0.83\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.32 \t Train (Adversarial) Loss:0.77\n",
      "\t Val (with Target) Loss:0.72 \t Val (with Target) Acc:0.85\n",
      "Epoch: 7 \n",
      " \t Train Loss:0.78 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.32 \t Train (Adversarial) Loss:0.77\n",
      "\t Val (with Target) Loss:0.71 \t Val (with Target) Acc:0.85\n",
      "Epoch: 8 \n",
      " \t Train Loss:0.76 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.32 \t Train (Adversarial) Loss:0.76\n",
      "\t Val (with Target) Loss:0.71 \t Val (with Target) Acc:0.85\n",
      "Epoch: 9 \n",
      " \t Train Loss:0.76 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:0.71 \t Val (with Target) Acc:0.85\n",
      "Epoch: 10 \n",
      " \t Train Loss:0.75 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.33 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.68 \t Val (with Target) Acc:0.85\n",
      "Epoch: 11 \n",
      " \t Train Loss:0.75 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.33 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.65 \t Val (with Target) Acc:0.85\n",
      "Epoch: 12 \n",
      " \t Train Loss:0.75 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.32 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.85\n",
      "Epoch: 13 \n",
      " \t Train Loss:0.74 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.31 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.85\n",
      "Epoch: 14 \n",
      " \t Train Loss:0.74 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.31 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.85\n",
      "Epoch: 15 \n",
      " \t Train Loss:0.74 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.31 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.66 \t Val (with Target) Acc:0.85\n",
      "Epoch: 16 \n",
      " \t Train Loss:0.74 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.31 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.59 \t Val (with Target) Acc:0.85\n",
      "Epoch: 17 \n",
      " \t Train Loss:0.74 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.33 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.84\n",
      "Epoch: 18 \n",
      " \t Train Loss:0.74 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.33 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.62 \t Val (with Target) Acc:0.84\n",
      "Epoch: 19 \n",
      " \t Train Loss:0.74 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.33 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.61 \t Val (with Target) Acc:0.85\n",
      "Epoch: 20 \n",
      " \t Train Loss:0.74 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.33 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.62 \t Val (with Target) Acc:0.84\n",
      "Epoch: 21 \n",
      " \t Train Loss:0.74 \t Train Acc:0.84\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.34 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.61 \t Val (with Target) Acc:0.84\n",
      "Epoch: 22 \n",
      " \t Train Loss:0.74 \t Train Acc:0.83\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.34 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.60 \t Val (with Target) Acc:0.84\n",
      "Epoch: 23 \n",
      " \t Train Loss:0.74 \t Train Acc:0.83\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.33 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.62 \t Val (with Target) Acc:0.83\n",
      "Epoch: 24 \n",
      " \t Train Loss:0.74 \t Train Acc:0.83\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.33 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.62 \t Val (with Target) Acc:0.83\n",
      "Epoch: 25 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.33 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.61 \t Val (with Target) Acc:0.83\n",
      "Epoch: 26 \n",
      " \t Train Loss:0.74 \t Train Acc:0.83\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.34 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.61 \t Val (with Target) Acc:0.82\n",
      "Epoch: 27 \n",
      " \t Train Loss:0.74 \t Train Acc:0.83\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.34 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.62 \t Val (with Target) Acc:0.83\n",
      "Epoch: 28 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.35 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.61 \t Val (with Target) Acc:0.82\n",
      "Epoch: 29 \n",
      " \t Train Loss:0.73 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.35 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.62 \t Val (with Target) Acc:0.82\n",
      "Epoch: 30 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.34 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.65 \t Val (with Target) Acc:0.81\n",
      "Epoch: 31 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.36 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.62 \t Val (with Target) Acc:0.81\n",
      "Epoch: 32 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.35 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.62 \t Val (with Target) Acc:0.82\n",
      "Epoch: 33 \n",
      " \t Train Loss:0.73 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.35 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.81\n",
      "Epoch: 34 \n",
      " \t Train Loss:0.73 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.35 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.81\n",
      "Epoch: 35 \n",
      " \t Train Loss:0.73 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.35 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.62 \t Val (with Target) Acc:0.81\n",
      "Epoch: 36 \n",
      " \t Train Loss:0.73 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.34 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.62 \t Val (with Target) Acc:0.81\n",
      "Epoch: 37 \n",
      " \t Train Loss:0.73 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.37 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.64 \t Val (with Target) Acc:0.81\n",
      "Epoch: 38 \n",
      " \t Train Loss:0.73 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.35 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.64 \t Val (with Target) Acc:0.81\n",
      "Epoch: 39 \n",
      " \t Train Loss:0.73 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.35 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.81\n",
      "Epoch: 40 \n",
      " \t Train Loss:0.73 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.36 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.81\n",
      "Epoch: 41 \n",
      " \t Train Loss:0.73 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.35 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.81\n",
      "Epoch: 42 \n",
      " \t Train Loss:0.73 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.37 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.81\n",
      "Epoch: 43 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.37 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.81\n",
      "Epoch: 44 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.37 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.81\n",
      "Epoch: 45 \n",
      " \t Train Loss:0.73 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.37 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.64 \t Val (with Target) Acc:0.81\n",
      "Epoch: 46 \n",
      " \t Train Loss:0.73 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.37 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.62 \t Val (with Target) Acc:0.81\n",
      "Epoch: 47 \n",
      " \t Train Loss:0.73 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.35 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.64 \t Val (with Target) Acc:0.81\n",
      "Epoch: 48 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.37 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.81\n",
      "Epoch: 49 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.36 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.81\n",
      "Epoch: 50 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.36 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.81\n",
      "\n",
      "Testing Accuracy on Previously Seen and Current Domains:\n",
      "Source Domain a:\n",
      "\t Test (with Source) Loss:0.56 \t Test (with Source) Acc:0.75\n",
      "Target Domain b:\n",
      "\t Test (with Target) Loss:0.66 \t Test (with Target) Acc:0.80\n",
      "Target Domain c:\n",
      "\t Test (with Target) Loss:0.66 \t Test (with Target) Acc:0.80\n",
      "===> generate new replay dataset!\n",
      "generated:  (8184, 1, 5120) (8184,)\n",
      "24552\n",
      "\n",
      "Phase 3 (Domain c to Domain d)\n",
      "Epoch: 1 \n",
      " \t Train Loss:0.80 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.31 \t Train (Adversarial) Loss:0.79\n",
      "\t Val (with Target) Loss:0.51 \t Val (with Target) Acc:0.82\n",
      "Epoch: 2 \n",
      " \t Train Loss:0.76 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.76\n",
      "\t Val (with Target) Loss:0.49 \t Val (with Target) Acc:0.82\n",
      "Epoch: 3 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.47 \t Val (with Target) Acc:0.82\n",
      "Epoch: 4 \n",
      " \t Train Loss:0.73 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.47 \t Val (with Target) Acc:0.82\n",
      "Epoch: 5 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.47 \t Val (with Target) Acc:0.82\n",
      "Epoch: 6 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.28 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.45 \t Val (with Target) Acc:0.82\n",
      "Epoch: 7 \n",
      " \t Train Loss:0.75 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.82\n",
      "Epoch: 8 \n",
      " \t Train Loss:0.76 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:0.45 \t Val (with Target) Acc:0.83\n",
      "Epoch: 9 \n",
      " \t Train Loss:0.76 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:0.45 \t Val (with Target) Acc:0.84\n",
      "Epoch: 10 \n",
      " \t Train Loss:0.76 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.76\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.83\n",
      "Epoch: 11 \n",
      " \t Train Loss:0.76 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.83\n",
      "Epoch: 12 \n",
      " \t Train Loss:0.76 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.31 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.83\n",
      "Epoch: 13 \n",
      " \t Train Loss:0.76 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:0.43 \t Val (with Target) Acc:0.83\n",
      "Epoch: 14 \n",
      " \t Train Loss:0.75 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.75\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.83\n",
      "Epoch: 15 \n",
      " \t Train Loss:0.75 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.43 \t Val (with Target) Acc:0.83\n",
      "Epoch: 16 \n",
      " \t Train Loss:0.75 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.31 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.83\n",
      "Epoch: 17 \n",
      " \t Train Loss:0.75 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.82\n",
      "Epoch: 18 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.83\n",
      "Epoch: 19 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.82\n",
      "Epoch: 20 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.31 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.81\n",
      "Epoch: 21 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.82\n",
      "Epoch: 22 \n",
      " \t Train Loss:0.75 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.83\n",
      "Epoch: 23 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.82\n",
      "Epoch: 24 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.82\n",
      "Epoch: 25 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.82\n",
      "Epoch: 26 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.45 \t Val (with Target) Acc:0.81\n",
      "Epoch: 27 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.44 \t Val (with Target) Acc:0.82\n",
      "Epoch: 28 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.45 \t Val (with Target) Acc:0.82\n",
      "Epoch: 29 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.28 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.81\n",
      "Epoch: 30 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.45 \t Val (with Target) Acc:0.82\n",
      "Epoch: 31 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.28 \t Train (Adversarial) Loss:0.74\n",
      "\t Val (with Target) Loss:0.45 \t Val (with Target) Acc:0.82\n",
      "Epoch: 32 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.82\n",
      "Epoch: 33 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.82\n",
      "Epoch: 34 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.80\n",
      "Epoch: 35 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.81\n",
      "Epoch: 36 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.81\n",
      "Epoch: 37 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.47 \t Val (with Target) Acc:0.81\n",
      "Epoch: 38 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.31 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.81\n",
      "Epoch: 39 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.81\n",
      "Epoch: 40 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.82\n",
      "Epoch: 41 \n",
      " \t Train Loss:0.74 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.81\n",
      "Epoch: 42 \n",
      " \t Train Loss:0.73 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.47 \t Val (with Target) Acc:0.81\n",
      "Epoch: 43 \n",
      " \t Train Loss:0.73 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.28 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.47 \t Val (with Target) Acc:0.81\n",
      "Epoch: 44 \n",
      " \t Train Loss:0.73 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.48 \t Val (with Target) Acc:0.80\n",
      "Epoch: 45 \n",
      " \t Train Loss:0.74 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.82\n",
      "Epoch: 46 \n",
      " \t Train Loss:0.73 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.30 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.47 \t Val (with Target) Acc:0.81\n",
      "Epoch: 47 \n",
      " \t Train Loss:0.73 \t Train Acc:0.81\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.82\n",
      "Epoch: 48 \n",
      " \t Train Loss:0.73 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.73\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.81\n",
      "Epoch: 49 \n",
      " \t Train Loss:0.73 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.29 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.47 \t Val (with Target) Acc:0.81\n",
      "Epoch: 50 \n",
      " \t Train Loss:0.73 \t Train Acc:0.82\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.28 \t Train (Adversarial) Loss:0.72\n",
      "\t Val (with Target) Loss:0.46 \t Val (with Target) Acc:0.82\n",
      "\n",
      "Testing Accuracy on Previously Seen and Current Domains:\n",
      "Source Domain a:\n",
      "\t Test (with Source) Loss:0.56 \t Test (with Source) Acc:0.75\n",
      "Target Domain b:\n",
      "\t Test (with Target) Loss:0.46 \t Test (with Target) Acc:0.82\n",
      "Target Domain c:\n",
      "\t Test (with Target) Loss:0.46 \t Test (with Target) Acc:0.82\n",
      "Target Domain d:\n",
      "\t Test (with Target) Loss:0.46 \t Test (with Target) Acc:0.82\n",
      "===> generate new replay dataset!\n",
      "generated:  (8184, 1, 5120) (8184,)\n",
      "32736\n"
     ]
    }
   ],
   "source": [
    "encoder_tgt.load_state_dict(encoder_src.state_dict())\n",
    "\n",
    "# adaptation\n",
    "for phase in range(len(target_domains)):\n",
    "    if(phase == 0): # Domain A to B\n",
    "        print(f'\\nPhase {phase + 1} (Domain {source_domain} to Domain {target_domains[phase]})')\n",
    "    else: # Domain B to C, and Domain C to D\n",
    "        print(f'\\nPhase {phase + 1} (Domain {target_domains[phase - 1]} to Domain {target_domains[phase]})')\n",
    "    \n",
    "    encoder_tgt = train_tgt(encoder_src, encoder_tgt, classifier, discriminator, phase)\n",
    "    \n",
    "    print('\\nTesting Accuracy on Previously Seen and Current Domains:')\n",
    "    print(f'Source Domain {source_domain}:')\n",
    "    src_test_loss, src_test_acc = evaluate_src(encoder_tgt, classifier, phase='Test')\n",
    "    print(f'\\t Test (with Source) Loss:{src_test_loss:0.2f} \\t Test (with Source) Acc:{src_test_acc:0.2f}') \n",
    "    for p in range(phase + 1):\n",
    "        print(f'Target Domain {target_domains[p]}:')\n",
    "        tgt_test_loss, tgt_test_acc = evaluate_tgt(encoder_tgt, classifier, test_dataloader_tgt[phase])\n",
    "        print(f'\\t Test (with Target) Loss:{tgt_test_loss:0.2f} \\t Test (with Target) Acc:{tgt_test_acc:0.2f}')\n",
    "\n",
    "    # update replay data and dataloader\n",
    "    data_tuple = generate_data_tuple(encoder_tgt, classifier, train_dataloader_tgt[phase])\n",
    "    replay_dataset.replay_dataset.update(data_tuple)\n",
    "    print(replay_dataset.__len__())\n",
    "    replay_dataloader = DataLoader(dataset=replay_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Test (with Source) Loss:0.56 \t Test (with Source) Acc:0.75\n",
      "\n",
      "Phase 1 (Domain a to Domain b)\n",
      "\t Test (with Target) Loss:0.60 \t Test (with Target) Acc:0.79\n",
      "\n",
      "Phase 2 (Domain b to Domain c)\n",
      "\t Test (with Target) Loss:0.60 \t Test (with Target) Acc:0.82\n",
      "\n",
      "Phase 3 (Domain c to Domain d)\n",
      "\t Test (with Target) Loss:0.46 \t Test (with Target) Acc:0.82\n"
     ]
    }
   ],
   "source": [
    "src_test_loss, src_test_acc = evaluate_src(encoder_tgt, classifier, phase='Test')\n",
    "print(f'\\t Test (with Source) Loss:{src_test_loss:0.2f} \\t Test (with Source) Acc:{src_test_acc:0.2f}') \n",
    "for phase in range(len(target_domains)):\n",
    "    if(phase == 0): # Domain A to B\n",
    "        print(f'\\nPhase {phase + 1} (Domain {source_domain} to Domain {target_domains[phase]})')\n",
    "    else: # Domain B to C, and Domain C to D\n",
    "        print(f'\\nPhase {phase + 1} (Domain {target_domains[phase - 1]} to Domain {target_domains[phase]})')\n",
    "    \n",
    "    tgt_test_loss, tgt_test_acc = evaluate_tgt(encoder_tgt, classifier, test_dataloader_tgt[phase])\n",
    "    print(f'\\t Test (with Target) Loss:{tgt_test_loss:0.2f} \\t Test (with Target) Acc:{tgt_test_acc:0.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('deep-learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbbf5940fb39bd3f383e6d88b474dca1e13ffd10acf1bdc8d3732bf030dd4f5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
