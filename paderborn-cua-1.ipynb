{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules and libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# functions to create datasets and models\n",
    "from data.data import *\n",
    "from models.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available')\n",
    "else:\n",
    "    print('CUDA is available')\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Parameters for this experiment\"\"\"\n",
    "# params for loading the data\n",
    "path = 'data/Paderborn_FD/'\n",
    "source_domain = 'a'\n",
    "target_domains = ['b', 'c', 'd']\n",
    "best_accuracies = {'a': 0, 'b': 0, 'c': 0, 'd': 0}\n",
    "\n",
    "# params for configuring the model\n",
    "input_dim = 1\n",
    "hidden_dim = 256\n",
    "output_dim = 3\n",
    "drop_prob = 0.5\n",
    "\n",
    "# params for training the model\n",
    "epochs_pre = 20 # pre-training\n",
    "epochs = 20\n",
    "\n",
    "# optimizing the model\n",
    "lr = 1e-4\n",
    "d_lr = 1e-4\n",
    "batch_size = 20\n",
    "beta1 = 0.5\n",
    "beta2 = 0.9\n",
    "lambda_rpy = 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source domain data for training, validating and testing\n",
    "train_dataloader_src, val_dataloader_src, test_dataloader_src = generate_dataloaders(path, source_domain, batch_size)\n",
    "\n",
    "# target domain data for validating and testing\n",
    "train_dataloader_tgt, val_dataloader_tgt, test_dataloader_tgt = [], [], []\n",
    "for target_domain in target_domains:\n",
    "    train_dataloader_temp, val_dataloader_temp, test_dataloader_temp = generate_dataloaders(path, target_domain, batch_size)\n",
    "    \n",
    "    train_dataloader_tgt.append(train_dataloader_temp)\n",
    "    val_dataloader_tgt.append(val_dataloader_temp)\n",
    "    test_dataloader_tgt.append(test_dataloader_temp)\n",
    "\n",
    "# replay data for CDA\n",
    "replay_dataset = ReplayDataset(train_dataloader_src.dataset)\n",
    "replay_dataloader = DataLoader(dataset=replay_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_src = Encoder_AMDA(\n",
    "    input_dim=input_dim, # 1D input (sensor readings)\n",
    "    hidden_dim=hidden_dim # hidden layers 64\n",
    ")\n",
    "\n",
    "classifier = Classifier_AMDA(\n",
    "    hidden_dim=hidden_dim, # hidden layers 64\n",
    "    output_dim=output_dim, # 3 classes (healthy, inner- and outer-bearing damages)\n",
    "    dropout=drop_prob # dropout prob 0.5\n",
    ")\n",
    "\n",
    "encoder_tgt = Encoder_AMDA(\n",
    "    input_dim=input_dim, # 1D input (sensor readings)\n",
    "    hidden_dim=hidden_dim, # hidden layers 64\n",
    ")\n",
    "\n",
    "discriminator = Discriminator(\n",
    "    hidden_dim=hidden_dim\n",
    ")\n",
    "\n",
    "if train_on_gpu:\n",
    "    encoder_src = encoder_src.to(device)\n",
    "    classifier = classifier.to(device)\n",
    "    encoder_tgt = encoder_tgt.to(device)\n",
    "    discriminator = discriminator.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for training source encoder and shared classifier\n",
    "def train_src(encoder, classifier):\n",
    "    \"\"\"Train the source encoder and shared classifier on source domain\"\"\"\n",
    "    encoder.train()\n",
    "    classifier.train()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(\n",
    "        list(encoder.parameters()) + list(classifier.parameters()),\n",
    "        lr=lr,\n",
    "        betas=(beta1, beta2)\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs_pre):\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "\n",
    "        for batch_idx, (x_src, y_src) in enumerate(train_dataloader_src):\n",
    "            if train_on_gpu:\n",
    "                x_src, y_src = x_src.to(device), y_src.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            e_src = encoder(x_src)\n",
    "            # print(e_src.shape)\n",
    "            # print(e_src)\n",
    "            pred_src = classifier(e_src)\n",
    "            # print(pred_src)\n",
    "            # print(y_src)\n",
    "            loss_src = criterion(pred_src, y_src)\n",
    "            loss_src.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss_src.detach().item()) # detach the loss from compute graph\n",
    "            accuracies.append(y_src.eq(pred_src.detach().argmax(dim=1)).float().mean())\n",
    "        \n",
    "        # print for each epoch\n",
    "        print(f'Epoch: {epoch + 1} \\n \\t Train Loss:{torch.tensor(losses).mean():0.2f} \\t Train Acc:{torch.tensor(accuracies).mean():0.2f}')\n",
    "\n",
    "        # for each epoch, evaluate your model on the validation data\n",
    "        val_loss, val_acc = evaluate_src(encoder, classifier, phase = 'Val')\n",
    "        print(f'\\t Val Loss:{val_loss:0.2f} \\t\\t Val Acc:{val_acc:0.2f}')\n",
    "\n",
    "    return encoder, classifier\n",
    "\n",
    "def evaluate_src(encoder, classifier, phase='Val'): # phase can be validate or test\n",
    "    \"\"\"Evaluate the trained network on source domain\"\"\"\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    dataloader = val_dataloader_src if phase == 'Val' else test_dataloader_src\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x_src, y_src) in enumerate(dataloader):\n",
    "            if train_on_gpu:\n",
    "                x_src, y_src = x_src.to(device), y_src.to(device)\n",
    "\n",
    "            e_src = encoder(x_src)\n",
    "            pred_src = classifier(e_src)\n",
    "            loss_src = criterion(pred_src, y_src)\n",
    "            \n",
    "            # append loss for each batch\n",
    "            losses.append(loss_src.detach().item()) # detach the loss from compute graph \n",
    "            accuracies.append(y_src.eq(pred_src.detach().argmax(dim=1)).float().mean())\n",
    "  \n",
    "        mean_loss = torch.tensor(losses).mean()\n",
    "        mean_acc = torch.tensor(accuracies).mean()\n",
    "        if dataloader == test_dataloader_src:\n",
    "            best_accuracies[source_domain] = max(best_accuracies[source_domain], mean_acc)\n",
    "        return mean_loss, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous Unsupervised Adaptation (CUA)\n",
    "# functions for training target encoder\n",
    "def train_tgt(encoder_src, encoder_tgt, classifier, discriminator, phase):\n",
    "    \"\"\"Train the target encoder on target domains with source encoder and test the network\"\"\"\n",
    "    encoder_tgt.train()\n",
    "    discriminator.train()\n",
    "    classifier.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(\n",
    "        encoder_tgt.parameters(),\n",
    "        lr=lr,\n",
    "        betas=(beta1, beta2)\n",
    "    )\n",
    "    d_optimizer = Adam(\n",
    "        discriminator.parameters(),\n",
    "        lr=d_lr,\n",
    "        betas=(beta1, beta2)\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        losses_d = []\n",
    "        losses_tgt = []\n",
    "        losses_rpy = []\n",
    "        accuracies = []\n",
    "        accuracies_d = []\n",
    "\n",
    "        for batch_idx, ((x_src, y_src), (x_tgt, y_tgt), (x_rpy, y_rpy)) in enumerate(zip(train_dataloader_src, train_dataloader_tgt[phase], replay_dataloader)):\n",
    "            if(train_on_gpu):\n",
    "                x_src, y_src = x_src.to(device), y_src.to(device)\n",
    "                x_tgt, y_tgt = x_tgt.to(device), y_tgt.to(device)\n",
    "                x_rpy, y_rpy = x_rpy.to(device), y_rpy.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            # part 1: sequential unsupervised adaptation\n",
    "            # learn e_src and _tgt: source and target mapping represenations\n",
    "            e_src = encoder_src(x_src)\n",
    "            e_tgt = encoder_tgt(x_tgt)\n",
    "            e_concat = torch.concat((e_src.detach(), e_tgt.detach()), 0)\n",
    "            # minimize distance between source and target empirical mapping distribution using adversarial discriminator\n",
    "            d_concat = discriminator(e_concat)\n",
    "\n",
    "            label_src = Variable(torch.ones(e_src.size(0)).long()).to(device)\n",
    "            label_tgt = Variable(torch.zeros(e_tgt.size(0)).long()).to(device)\n",
    "            label_concat = torch.cat((label_src, label_tgt), 0)\n",
    "\n",
    "            loss_d = criterion(d_concat, label_concat)\n",
    "            loss_d.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            e_tgt = encoder_tgt(x_tgt)\n",
    "            pred_tgt = classifier(e_tgt)\n",
    "            d_tgt = discriminator(e_tgt)\n",
    "            label_tgt = Variable(torch.ones(e_tgt.size(0)).long()).to(device)\n",
    "            loss_tgt = criterion(d_tgt, label_tgt)\n",
    "\n",
    "            # part 2: continuous replay adaptation\n",
    "            # additional replay loss to retain 'prior knowledge'\n",
    "            pred_rpy = classifier(encoder_tgt(x_rpy))\n",
    "            loss_rpy = criterion(pred_rpy, y_rpy)\n",
    "            loss = loss_tgt + lambda_rpy * loss_rpy\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # training (with replay) losses and accuracies\n",
    "            losses.append(loss.detach().item()) # detach the loss from compute graph\n",
    "            losses_d.append(loss_d.detach().item())\n",
    "            losses_tgt.append(loss_tgt.detach().item())\n",
    "            losses_rpy.append(loss_rpy.detach().item())\n",
    "            accuracies.append(y_tgt.eq(pred_tgt.detach().argmax(dim=1)).float().mean())\n",
    "            accuracies_d.append(torch.squeeze(d_concat.max(1)[1]).eq(label_concat.detach()).float().mean())\n",
    "        \n",
    "        # print for each epoch\n",
    "        print(f'Epoch: {epoch + 1} \\n \\t Train Loss:{torch.tensor(losses).mean():0.2f} \\t Train Acc:{torch.tensor(accuracies).mean():0.2f}')\n",
    "        print(f'\\t Discriminator Loss:{torch.tensor(losses_d).mean():0.2f} \\t Train (Replay) Loss:{torch.tensor(losses_rpy).mean():0.2f} \\t Train (Adversarial) Loss:{torch.tensor(losses_tgt).mean():0.2f}')\n",
    "        \n",
    "        # for each epoch, evaluate your model on the validation data\n",
    "        val_loss, val_acc = evaluate_tgt(encoder_tgt, classifier, val_dataloader_tgt[phase])\n",
    "        print(f'\\t Val (with Target) Loss:{val_loss:0.2f} \\t Val (with Target) Acc:{val_acc:0.2f}')\n",
    "\n",
    "    return encoder_tgt\n",
    "    \n",
    "# testing model on target domains\n",
    "\n",
    "def evaluate_tgt(encoder, classifier, dataloader):\n",
    "    \"\"\"Evaluate the network on current target domain\"\"\"\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, y) in enumerate(dataloader): # target dataloader\n",
    "            if(train_on_gpu):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "            pred_tgt = classifier(encoder(x))\n",
    "            loss_tgt = criterion(pred_tgt, y)\n",
    "            \n",
    "            # append loss for each batch\n",
    "            losses.append(loss_tgt.detach().item()) # detach the loss from compute graph \n",
    "            accuracies.append(y.eq(pred_tgt.detach().argmax(dim=1)).float().mean())\n",
    "            \n",
    "        mean_loss = torch.tensor(losses).mean()\n",
    "        mean_acc = torch.tensor(accuracies).mean()\n",
    "        if dataloader in test_dataloader_tgt:\n",
    "            index = test_dataloader_tgt.index(dataloader)\n",
    "            best_accuracies[target_domains[index]] = max(best_accuracies[target_domains[index]], mean_acc)\n",
    "\n",
    "        return mean_loss, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample previously seen examples and their respective classification scores as 'soft labels' from the target domains\n",
    "def generate_data_tuple(encoder_tgt, classifier, dataloader):\n",
    "    print('===> generate new replay dataset!')\n",
    "    encoder_tgt.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    m = nn.Softmax(dim=1)\n",
    "\n",
    "    all_x, all_pred = [], []\n",
    "    accuracies = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x_tgt, y_tgt) in enumerate(dataloader):\n",
    "            if(train_on_gpu):\n",
    "                x_tgt, y_tgt = x_tgt.to(device), y_tgt.to(device)\n",
    "\n",
    "            # perform classification with the target mapping representations\n",
    "            pred_tgt = classifier(encoder_tgt(x_tgt))\n",
    "            pred_tgt_softmax = m(pred_tgt)\n",
    "            confidence_level = pred_tgt_softmax.amax(axis=1)\n",
    "\n",
    "            all_x.append(to_np(torch.squeeze(x_tgt[np.nonzero(confidence_level > 0.9)], 1)))\n",
    "            all_pred.append(to_np(torch.squeeze(pred_tgt.detach().argmax(dim=1)[np.nonzero(confidence_level > 0.9)], 1)))\n",
    "            accuracies.append(y_tgt[np.nonzero(confidence_level > 0.9)].eq(torch.squeeze(pred_tgt.detach().argmax(dim=1)[np.nonzero(confidence_level > 0.9)], 0)).float().mean())\n",
    "            \n",
    "        x, pred = np.concatenate(all_x, 0), np.concatenate(all_pred, 0)\n",
    "        num_samples = x.shape[0]\n",
    "        num_subsamples = int(1 * num_samples)\n",
    "        np.random.seed(4154)\n",
    "        perm = np.random.permutation(num_samples)\n",
    "        x, pred = x[perm[0:num_subsamples]], pred[perm[0:num_subsamples]]\n",
    "\n",
    "        print('generated: ', x.shape, pred.shape, 'accuracy: ', torch.tensor(accuracies).mean())\n",
    "        return x, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-training\n",
    "# encoder_src, classifier = train_src(encoder_src, classifier)\n",
    "# torch.save(encoder_src.state_dict(), './dump/source_encoder.pt')\n",
    "# torch.save(classifier.state_dict(), './dump/classifier.pt')\n",
    "encoder_src.load_state_dict(torch.load('./dump/source_encoder.pt'))\n",
    "classifier.load_state_dict(torch.load('./dump/classifier.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 1 (Domain a to Domain b)\n",
      "Epoch: 1 \n",
      " \t Train Loss:0.86 \t Train Acc:0.65\n",
      "\t Discriminator Loss:0.62 \t Train (Replay) Loss:0.54 \t Train (Adversarial) Loss:0.84\n",
      "\t Val (with Target) Loss:5.00 \t Val (with Target) Acc:0.64\n",
      "Epoch: 2 \n",
      " \t Train Loss:0.86 \t Train Acc:0.71\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.36 \t Train (Adversarial) Loss:0.85\n",
      "\t Val (with Target) Loss:3.77 \t Val (with Target) Acc:0.72\n",
      "Epoch: 3 \n",
      " \t Train Loss:0.93 \t Train Acc:0.76\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.62 \t Train (Adversarial) Loss:0.91\n",
      "\t Val (with Target) Loss:2.82 \t Val (with Target) Acc:0.76\n",
      "Epoch: 4 \n",
      " \t Train Loss:0.98 \t Train Acc:0.77\n",
      "\t Discriminator Loss:0.60 \t Train (Replay) Loss:0.82 \t Train (Adversarial) Loss:0.95\n",
      "\t Val (with Target) Loss:2.69 \t Val (with Target) Acc:0.77\n",
      "Epoch: 5 \n",
      " \t Train Loss:0.98 \t Train Acc:0.87\n",
      "\t Discriminator Loss:0.63 \t Train (Replay) Loss:2.63 \t Train (Adversarial) Loss:0.90\n",
      "\t Val (with Target) Loss:2.89 \t Val (with Target) Acc:0.92\n",
      "Epoch: 6 \n",
      " \t Train Loss:0.98 \t Train Acc:0.90\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:2.79 \t Train (Adversarial) Loss:0.90\n",
      "\t Val (with Target) Loss:2.19 \t Val (with Target) Acc:0.93\n",
      "Epoch: 7 \n",
      " \t Train Loss:0.96 \t Train Acc:0.94\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:1.30 \t Train (Adversarial) Loss:0.92\n",
      "\t Val (with Target) Loss:1.35 \t Val (with Target) Acc:0.94\n",
      "Epoch: 8 \n",
      " \t Train Loss:0.91 \t Train Acc:0.93\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.59 \t Train (Adversarial) Loss:0.89\n",
      "\t Val (with Target) Loss:2.88 \t Val (with Target) Acc:0.93\n",
      "Epoch: 9 \n",
      " \t Train Loss:0.87 \t Train Acc:0.92\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.40 \t Train (Adversarial) Loss:0.85\n",
      "\t Val (with Target) Loss:1.58 \t Val (with Target) Acc:0.91\n",
      "Epoch: 10 \n",
      " \t Train Loss:0.83 \t Train Acc:0.93\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.34 \t Train (Adversarial) Loss:0.82\n",
      "\t Val (with Target) Loss:2.18 \t Val (with Target) Acc:0.93\n",
      "Epoch: 11 \n",
      " \t Train Loss:0.82 \t Train Acc:0.93\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.27 \t Train (Adversarial) Loss:0.81\n",
      "\t Val (with Target) Loss:1.38 \t Val (with Target) Acc:0.93\n",
      "Epoch: 12 \n",
      " \t Train Loss:0.82 \t Train Acc:0.93\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.23 \t Train (Adversarial) Loss:0.82\n",
      "\t Val (with Target) Loss:1.35 \t Val (with Target) Acc:0.90\n",
      "Epoch: 13 \n",
      " \t Train Loss:0.81 \t Train Acc:0.94\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.21 \t Train (Adversarial) Loss:0.81\n",
      "\t Val (with Target) Loss:1.83 \t Val (with Target) Acc:0.94\n",
      "Epoch: 14 \n",
      " \t Train Loss:0.82 \t Train Acc:0.94\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.17 \t Train (Adversarial) Loss:0.81\n",
      "\t Val (with Target) Loss:1.26 \t Val (with Target) Acc:0.93\n",
      "Epoch: 15 \n",
      " \t Train Loss:0.81 \t Train Acc:0.94\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.14 \t Train (Adversarial) Loss:0.81\n",
      "\t Val (with Target) Loss:0.63 \t Val (with Target) Acc:0.95\n",
      "Epoch: 16 \n",
      " \t Train Loss:0.81 \t Train Acc:0.94\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.81\n",
      "\t Val (with Target) Loss:0.95 \t Val (with Target) Acc:0.95\n",
      "Epoch: 17 \n",
      " \t Train Loss:0.81 \t Train Acc:0.94\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.11 \t Train (Adversarial) Loss:0.81\n",
      "\t Val (with Target) Loss:1.19 \t Val (with Target) Acc:0.94\n",
      "Epoch: 18 \n",
      " \t Train Loss:0.82 \t Train Acc:0.95\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.09 \t Train (Adversarial) Loss:0.81\n",
      "\t Val (with Target) Loss:0.76 \t Val (with Target) Acc:0.91\n",
      "Epoch: 19 \n",
      " \t Train Loss:0.82 \t Train Acc:0.95\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.10 \t Train (Adversarial) Loss:0.82\n",
      "\t Val (with Target) Loss:1.46 \t Val (with Target) Acc:0.94\n",
      "Epoch: 20 \n",
      " \t Train Loss:0.82 \t Train Acc:0.95\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.10 \t Train (Adversarial) Loss:0.82\n",
      "\t Val (with Target) Loss:1.19 \t Val (with Target) Acc:0.95\n",
      "\n",
      "Testing Accuracy on Previously Seen and Current Domains:\n",
      "Source Domain a:\n",
      "\t Test (with Source) Loss:0.09 \t Test (with Source) Acc:0.97\n",
      "Target Domain b:\n",
      "\t Test (with Target) Loss:1.05 \t Test (with Target) Acc:0.95\n",
      "===> generate new replay dataset!\n",
      "generated:  (8025, 1, 5120) (8025,) accuracy:  tensor(0.9569)\n",
      "16209\n",
      "\n",
      "Phase 2 (Domain b to Domain c)\n",
      "Epoch: 1 \n",
      " \t Train Loss:0.86 \t Train Acc:0.85\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:0.18 \t Train (Adversarial) Loss:0.86\n",
      "\t Val (with Target) Loss:2.50 \t Val (with Target) Acc:0.86\n",
      "Epoch: 2 \n",
      " \t Train Loss:0.89 \t Train Acc:0.85\n",
      "\t Discriminator Loss:0.65 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.88\n",
      "\t Val (with Target) Loss:2.39 \t Val (with Target) Acc:0.86\n",
      "Epoch: 3 \n",
      " \t Train Loss:0.88 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.87\n",
      "\t Val (with Target) Loss:2.56 \t Val (with Target) Acc:0.87\n",
      "Epoch: 4 \n",
      " \t Train Loss:0.87 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.87\n",
      "\t Val (with Target) Loss:2.01 \t Val (with Target) Acc:0.86\n",
      "Epoch: 5 \n",
      " \t Train Loss:0.88 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.88\n",
      "\t Val (with Target) Loss:2.45 \t Val (with Target) Acc:0.86\n",
      "Epoch: 6 \n",
      " \t Train Loss:0.87 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.66 \t Train (Replay) Loss:0.13 \t Train (Adversarial) Loss:0.86\n",
      "\t Val (with Target) Loss:2.69 \t Val (with Target) Acc:0.86\n",
      "Epoch: 7 \n",
      " \t Train Loss:0.86 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.86\n",
      "\t Val (with Target) Loss:2.96 \t Val (with Target) Acc:0.82\n",
      "Epoch: 8 \n",
      " \t Train Loss:0.87 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.11 \t Train (Adversarial) Loss:0.87\n",
      "\t Val (with Target) Loss:2.80 \t Val (with Target) Acc:0.86\n",
      "Epoch: 9 \n",
      " \t Train Loss:0.85 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.85\n",
      "\t Val (with Target) Loss:2.62 \t Val (with Target) Acc:0.87\n",
      "Epoch: 10 \n",
      " \t Train Loss:0.86 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.11 \t Train (Adversarial) Loss:0.86\n",
      "\t Val (with Target) Loss:2.87 \t Val (with Target) Acc:0.86\n",
      "Epoch: 11 \n",
      " \t Train Loss:0.86 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.85\n",
      "\t Val (with Target) Loss:2.65 \t Val (with Target) Acc:0.86\n",
      "Epoch: 12 \n",
      " \t Train Loss:0.85 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.85\n",
      "\t Val (with Target) Loss:2.38 \t Val (with Target) Acc:0.86\n",
      "Epoch: 13 \n",
      " \t Train Loss:0.85 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.13 \t Train (Adversarial) Loss:0.85\n",
      "\t Val (with Target) Loss:2.51 \t Val (with Target) Acc:0.87\n",
      "Epoch: 14 \n",
      " \t Train Loss:0.85 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.13 \t Train (Adversarial) Loss:0.84\n",
      "\t Val (with Target) Loss:2.57 \t Val (with Target) Acc:0.86\n",
      "Epoch: 15 \n",
      " \t Train Loss:0.84 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.13 \t Train (Adversarial) Loss:0.84\n",
      "\t Val (with Target) Loss:2.30 \t Val (with Target) Acc:0.87\n",
      "Epoch: 16 \n",
      " \t Train Loss:0.85 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.85\n",
      "\t Val (with Target) Loss:2.28 \t Val (with Target) Acc:0.87\n",
      "Epoch: 17 \n",
      " \t Train Loss:0.84 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.13 \t Train (Adversarial) Loss:0.84\n",
      "\t Val (with Target) Loss:2.75 \t Val (with Target) Acc:0.86\n",
      "Epoch: 18 \n",
      " \t Train Loss:0.84 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.84\n",
      "\t Val (with Target) Loss:2.72 \t Val (with Target) Acc:0.87\n",
      "Epoch: 19 \n",
      " \t Train Loss:0.84 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.84\n",
      "\t Val (with Target) Loss:2.63 \t Val (with Target) Acc:0.86\n",
      "Epoch: 20 \n",
      " \t Train Loss:0.84 \t Train Acc:0.86\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.11 \t Train (Adversarial) Loss:0.84\n",
      "\t Val (with Target) Loss:2.58 \t Val (with Target) Acc:0.86\n",
      "\n",
      "Testing Accuracy on Previously Seen and Current Domains:\n",
      "Source Domain a:\n",
      "\t Test (with Source) Loss:0.21 \t Test (with Source) Acc:0.95\n",
      "Target Domain b:\n",
      "\t Test (with Target) Loss:1.16 \t Test (with Target) Acc:0.94\n",
      "Target Domain c:\n",
      "\t Test (with Target) Loss:2.58 \t Test (with Target) Acc:0.86\n",
      "===> generate new replay dataset!\n",
      "generated:  (8017, 1, 5120) (8017,) accuracy:  tensor(0.8617)\n",
      "24226\n",
      "\n",
      "Phase 3 (Domain c to Domain d)\n",
      "Epoch: 1 \n",
      " \t Train Loss:0.84 \t Train Acc:0.97\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.13 \t Train (Adversarial) Loss:0.83\n",
      "\t Val (with Target) Loss:0.40 \t Val (with Target) Acc:0.92\n",
      "Epoch: 2 \n",
      " \t Train Loss:0.83 \t Train Acc:0.98\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.83\n",
      "\t Val (with Target) Loss:0.02 \t Val (with Target) Acc:1.00\n",
      "Epoch: 3 \n",
      " \t Train Loss:0.83 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.10 \t Train (Adversarial) Loss:0.83\n",
      "\t Val (with Target) Loss:0.05 \t Val (with Target) Acc:0.98\n",
      "Epoch: 4 \n",
      " \t Train Loss:0.84 \t Train Acc:0.98\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.13 \t Train (Adversarial) Loss:0.83\n",
      "\t Val (with Target) Loss:0.08 \t Val (with Target) Acc:0.98\n",
      "Epoch: 5 \n",
      " \t Train Loss:0.84 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.11 \t Train (Adversarial) Loss:0.83\n",
      "\t Val (with Target) Loss:0.02 \t Val (with Target) Acc:0.99\n",
      "Epoch: 6 \n",
      " \t Train Loss:0.83 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.13 \t Train (Adversarial) Loss:0.83\n",
      "\t Val (with Target) Loss:0.06 \t Val (with Target) Acc:0.98\n",
      "Epoch: 7 \n",
      " \t Train Loss:0.83 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.10 \t Train (Adversarial) Loss:0.83\n",
      "\t Val (with Target) Loss:0.00 \t Val (with Target) Acc:1.00\n",
      "Epoch: 8 \n",
      " \t Train Loss:0.84 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.83\n",
      "\t Val (with Target) Loss:0.03 \t Val (with Target) Acc:0.99\n",
      "Epoch: 9 \n",
      " \t Train Loss:0.83 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.11 \t Train (Adversarial) Loss:0.82\n",
      "\t Val (with Target) Loss:0.03 \t Val (with Target) Acc:0.99\n",
      "Epoch: 10 \n",
      " \t Train Loss:0.82 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.11 \t Train (Adversarial) Loss:0.82\n",
      "\t Val (with Target) Loss:0.00 \t Val (with Target) Acc:1.00\n",
      "Epoch: 11 \n",
      " \t Train Loss:0.83 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.10 \t Train (Adversarial) Loss:0.83\n",
      "\t Val (with Target) Loss:0.02 \t Val (with Target) Acc:0.99\n",
      "Epoch: 12 \n",
      " \t Train Loss:0.83 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.10 \t Train (Adversarial) Loss:0.82\n",
      "\t Val (with Target) Loss:0.01 \t Val (with Target) Acc:1.00\n",
      "Epoch: 13 \n",
      " \t Train Loss:0.83 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.11 \t Train (Adversarial) Loss:0.82\n",
      "\t Val (with Target) Loss:0.04 \t Val (with Target) Acc:0.99\n",
      "Epoch: 14 \n",
      " \t Train Loss:0.82 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.13 \t Train (Adversarial) Loss:0.82\n",
      "\t Val (with Target) Loss:0.01 \t Val (with Target) Acc:0.99\n",
      "Epoch: 15 \n",
      " \t Train Loss:0.83 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.67 \t Train (Replay) Loss:0.10 \t Train (Adversarial) Loss:0.82\n",
      "\t Val (with Target) Loss:0.02 \t Val (with Target) Acc:0.99\n",
      "Epoch: 16 \n",
      " \t Train Loss:0.83 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.11 \t Train (Adversarial) Loss:0.82\n",
      "\t Val (with Target) Loss:0.00 \t Val (with Target) Acc:1.00\n",
      "Epoch: 17 \n",
      " \t Train Loss:0.82 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.82\n",
      "\t Val (with Target) Loss:0.01 \t Val (with Target) Acc:1.00\n",
      "Epoch: 18 \n",
      " \t Train Loss:0.83 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.12 \t Train (Adversarial) Loss:0.82\n",
      "\t Val (with Target) Loss:0.06 \t Val (with Target) Acc:0.99\n",
      "Epoch: 19 \n",
      " \t Train Loss:0.83 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.11 \t Train (Adversarial) Loss:0.83\n",
      "\t Val (with Target) Loss:0.01 \t Val (with Target) Acc:1.00\n",
      "Epoch: 20 \n",
      " \t Train Loss:0.82 \t Train Acc:0.99\n",
      "\t Discriminator Loss:0.68 \t Train (Replay) Loss:0.13 \t Train (Adversarial) Loss:0.82\n",
      "\t Val (with Target) Loss:0.01 \t Val (with Target) Acc:1.00\n",
      "\n",
      "Testing Accuracy on Previously Seen and Current Domains:\n",
      "Source Domain a:\n",
      "\t Test (with Source) Loss:0.13 \t Test (with Source) Acc:0.97\n",
      "Target Domain b:\n",
      "\t Test (with Target) Loss:0.62 \t Test (with Target) Acc:0.95\n",
      "Target Domain c:\n",
      "\t Test (with Target) Loss:0.93 \t Test (with Target) Acc:0.86\n",
      "Target Domain d:\n",
      "\t Test (with Target) Loss:0.01 \t Test (with Target) Acc:1.00\n",
      "===> generate new replay dataset!\n",
      "generated:  (8143, 1, 5120) (8143,) accuracy:  tensor(0.9990)\n",
      "32369\n"
     ]
    }
   ],
   "source": [
    "encoder_tgt.load_state_dict(encoder_src.state_dict())\n",
    "\n",
    "# adaptation\n",
    "for phase in range(len(target_domains)):\n",
    "    if(phase == 0): # Domain A to B\n",
    "        print(f'\\nPhase {phase + 1} (Domain {source_domain} to Domain {target_domains[phase]})')\n",
    "    else: # Domain B to C, and Domain C to D\n",
    "        print(f'\\nPhase {phase + 1} (Domain {target_domains[phase - 1]} to Domain {target_domains[phase]})')\n",
    "    \n",
    "    encoder_tgt = train_tgt(encoder_src, encoder_tgt, classifier, discriminator, phase)\n",
    "    \n",
    "    print('\\nTesting Accuracy on Previously Seen and Current Domains:')\n",
    "    print(f'Source Domain {source_domain}:')\n",
    "    src_test_loss, src_test_acc = evaluate_src(encoder_tgt, classifier, phase='Test')\n",
    "    print(f'\\t Test (with Source) Loss:{src_test_loss:0.2f} \\t Test (with Source) Acc:{src_test_acc:0.2f}') \n",
    "    for p in range(phase + 1):\n",
    "        print(f'Target Domain {target_domains[p]}:')\n",
    "        tgt_test_loss, tgt_test_acc = evaluate_tgt(encoder_tgt, classifier, test_dataloader_tgt[p])\n",
    "        print(f'\\t Test (with Target) Loss:{tgt_test_loss:0.2f} \\t Test (with Target) Acc:{tgt_test_acc:0.2f}')\n",
    "        \n",
    "    # update replay data and dataloader\n",
    "    data_tuple = generate_data_tuple(encoder_tgt, classifier, train_dataloader_tgt[phase])\n",
    "    replay_dataset.replay_dataset.update(data_tuple)\n",
    "    print(replay_dataset.__len__())\n",
    "    replay_dataloader = DataLoader(dataset=replay_dataset, shuffle=True, batch_size=batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Test (with Source) Loss:0.13 \t Test (with Source) Acc:0.97\n",
      "\n",
      "Phase 1 (Domain a to Domain b)\n",
      "\t Test (with Target) Loss:0.62 \t Test (with Target) Acc:0.95\n",
      "\n",
      "Phase 2 (Domain b to Domain c)\n",
      "\t Test (with Target) Loss:0.92 \t Test (with Target) Acc:0.86\n",
      "\n",
      "Phase 3 (Domain c to Domain d)\n",
      "\t Test (with Target) Loss:0.01 \t Test (with Target) Acc:1.00\n"
     ]
    }
   ],
   "source": [
    "src_test_loss, src_test_acc = evaluate_src(encoder_tgt, classifier, phase='Test')\n",
    "print(f'\\t Test (with Source) Loss:{src_test_loss:0.2f} \\t Test (with Source) Acc:{src_test_acc:0.2f}') \n",
    "for phase in range(len(target_domains)):\n",
    "    if(phase == 0): # Domain A to B\n",
    "        print(f'\\nPhase {phase + 1} (Domain {source_domain} to Domain {target_domains[phase]})')\n",
    "    else: # Domain B to C, and Domain C to D\n",
    "        print(f'\\nPhase {phase + 1} (Domain {target_domains[phase - 1]} to Domain {target_domains[phase]})')\n",
    "    \n",
    "    tgt_test_loss, tgt_test_acc = evaluate_tgt(encoder_tgt, classifier, test_dataloader_tgt[phase])\n",
    "    print(f'\\t Test (with Target) Loss:{tgt_test_loss:0.2f} \\t Test (with Target) Acc:{tgt_test_acc:0.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': tensor(0.9737),\n",
       " 'b': tensor(0.9464),\n",
       " 'c': tensor(0.8604),\n",
       " 'd': tensor(0.9985)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n"
     ]
    }
   ],
   "source": [
    "print(f\"{best_accuracies['a']:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = list(best_accuracies.keys())\n",
    "accuracies = list(best_accuracies.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x210c8b327c0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(domains, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('cda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1e22e9a36d2ff643870da04044e3ba6e20e322fec5858ad637bee34c459619d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
